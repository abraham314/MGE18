{"paragraphs":[{"text":"%pyspark\n\n\nfrom pyspark.context import SparkContext\nfrom pyspark.sql.session import SparkSession\nfrom pyspark.sql.functions import *\n\nfrom pyspark.ml.regression import RandomForestRegressor\nfrom pyspark.ml.regression import GBTRegressor\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.feature import OneHotEncoder\nfrom pyspark.ml import Pipeline\n\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.evaluation import RegressionEvaluator  \nfrom timeit import default_timer as timer\n\n#Para las pruebas locales\n#sc = SparkContext('local[*]')\n#spark = SparkSession(sc)\n\n#Se carga archivo, usamos la carpeta de la tarea pasada para no volver a cargar el archivo\nflights = spark.read.csv(\"s3a://vq-mcd2018/tarea_6/Datos/flights/flights/flights.csv\", header=True, inferSchema=True,nullValue = 'null')\n\n\n#Se seleccionan las variables que usaremos, dejamos fuera las que tienen NA en la mayoria de sus observaciones\ndata = flights.select(['YEAR', 'MONTH', 'DAY', 'DAY_OF_WEEK', 'AIRLINE', 'FLIGHT_NUMBER', 'TAIL_NUMBER', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT', 'WHEELS_OFF', 'SCHEDULED_TIME', 'ELAPSED_TIME', 'AIR_TIME', 'DISTANCE', 'WHEELS_ON', 'TAXI_IN', 'SCHEDULED_ARRIVAL', 'ARRIVAL_TIME', 'ARRIVAL_DELAY', 'DIVERTED', 'CANCELLED'])\n\ndata = data.na.drop(subset=['YEAR', 'MONTH', 'DAY', 'DAY_OF_WEEK', 'AIRLINE', 'FLIGHT_NUMBER', 'TAIL_NUMBER', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT', 'WHEELS_OFF', 'SCHEDULED_TIME', 'ELAPSED_TIME', 'AIR_TIME', 'DISTANCE', 'WHEELS_ON', 'TAXI_IN', 'SCHEDULED_ARRIVAL', 'ARRIVAL_TIME', 'ARRIVAL_DELAY', 'DIVERTED', 'CANCELLED'])\n\n\n#Dividimos en entrenamiento y prueba\n(trainingData, testData) = data.randomSplit([0.7, 0.3])\n\n\n\n#Se hace el String Index para las variables categóricas usando los datos de entrenamiento\nairline_indexer = StringIndexer(inputCol='AIRLINE', outputCol='AIRLINE_numeric', handleInvalid='skip').fit(trainingData)\n\ntailNumber_indexer = StringIndexer(inputCol='TAIL_NUMBER', outputCol='TAIL_NUMBER_numeric', handleInvalid='skip').fit(trainingData)\n\noriginAirport_indexer = StringIndexer(inputCol='ORIGIN_AIRPORT', outputCol='ORIGIN_AIRPORT_numeric', handleInvalid='skip').fit(trainingData)\n\ndestinationAirport_indexer = StringIndexer(inputCol='DESTINATION_AIRPORT', outputCol='DESTINATION_AIRPORT_numeric', handleInvalid='skip').fit(trainingData)\n\n#Hacemos el Vector Assembler, se deja fuera la variable TAIL_NUMBER por la gran cantidad de categorias que tiene\nassembler = VectorAssembler(inputCols=['YEAR', 'MONTH', 'DAY', 'DAY_OF_WEEK', 'AIRLINE_numeric', 'FLIGHT_NUMBER', 'ORIGIN_AIRPORT_numeric', 'DESTINATION_AIRPORT_numeric', 'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'TAXI_OUT', 'WHEELS_OFF', 'SCHEDULED_TIME', 'ELAPSED_TIME', 'AIR_TIME', 'DISTANCE', 'WHEELS_ON', 'TAXI_IN', 'SCHEDULED_ARRIVAL', 'ARRIVAL_TIME', 'ARRIVAL_DELAY', 'DIVERTED', 'CANCELLED'], outputCol='features')\n\n#Hacemos grid de los modelos a correr\nclfs = {'RF': RandomForestRegressor(labelCol='DEPARTURE_DELAY', featuresCol='features', numTrees=5),\n        'GB': GBTRegressor(labelCol='DEPARTURE_DELAY', featuresCol='features', maxIter=5), \n        }\n\n#Hacemos grid de parametros a utilizar por modelo\nparamGrid = { \n    'RF': ParamGridBuilder().addGrid(clfs['RF'].maxDepth, [2, 3, 5]).addGrid(clfs['RF'].maxBins, [800, 900,1000]).build(),\n    'GB': ParamGridBuilder().addGrid(clfs['GB'].maxDepth, [2, 3, 5]).addGrid(clfs['GB'].maxBins, [800, 900,1000]).build(),\n         }\n\n#Modelos a correr\nmodels_to_run = ['RF','GB']\n\n#Definimos nuestra funcion de magic_loop\ndef magic_loop(models_to_run, clfs, grid, trainingData, testData):\n    #Se crea un dataframe para guardar los resultados de RMSE del magic_loop y una lista para los parámetros y mejores modelos\n    df = spark.createDataFrame([(\"a_Modelo0\",100.002)], [\"Modelo\", \"RMSE\"])\n    mejores=list()\n    \n    #Se hace un for para que recorra todos los modelos a correr\n    for index,clf in enumerate([clfs[x] for x in models_to_run]):\n        \n  \n        modelo=clfs[models_to_run[index]]\n\n        #Se define la métrica de evaluacion\n        evaluator=RegressionEvaluator(metricName=\"rmse\",labelCol=modelo.getLabelCol(),predictionCol=modelo.getPredictionCol())\n\t\n    \t#Se define pasos y pipeline\n        stages = [airline_indexer, tailNumber_indexer, originAirport_indexer, destinationAirport_indexer, assembler, modelo]\n\n        pipeline = Pipeline(stages=stages)\n\n        #Se hace cross validation\n        crossval = CrossValidator(estimator=pipeline,  \n\t\t                 estimatorParamMaps=grid[models_to_run[index]],\n\t\t                 evaluator=evaluator,\n\t\t                 numFolds=10)\n\t\t                 \n        #Se hace fit al mejor modelo del cross validation con los datos de entrenamiento\n        cvModel = crossval.fit(trainingData)\n        \n        #Se guarda el mejor modelo y parametros\n        mejores.append(cvModel.bestModel)\n        \n        #Se hacen las predicciones\n        predictions = cvModel.transform(testData)\n        \n\t    #Se calcula el RMSE\n        rmse = evaluator.evaluate(predictions)\n\n        #Se guarda el RMSE y elmodelo\n        df2 = spark.createDataFrame([\n\t    (models_to_run[index], rmse)\n        ], [\"Modelo\", \"RMSE\"])\n\n        df = df.union(df2)\n    return [mejores,df]\n\n%pyspark\n#Se corre magic_loop\nresultado,df=magic_loop(models_to_run, clfs, paramGrid, trainingData, testData)\n\n\n","dateUpdated":"2018-04-28T03:03:00+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1524848793788_1276365358","id":"20180427-074856_259383496","dateCreated":"2018-04-27T17:06:33+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:175","user":"anonymous","dateFinished":"2018-04-28T02:15:34+0000","dateStarted":"2018-04-27T23:55:07+0000"},{"text":"%pyspark\n#Vemos los mejores parametros para GB\nprint(resultado[1].stages[-1]._java_obj.extractParamMap())","dateUpdated":"2018-04-28T02:26:19+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"{\n\tGBTRegressor_44f5a2b1652e23f52302-cacheNodeIds: false,\n\tGBTRegressor_44f5a2b1652e23f52302-checkpointInterval: 10,\n\tGBTRegressor_44f5a2b1652e23f52302-featuresCol: features,\n\tGBTRegressor_44f5a2b1652e23f52302-impurity: variance,\n\tGBTRegressor_44f5a2b1652e23f52302-labelCol: DEPARTURE_DELAY,\n\tGBTRegressor_44f5a2b1652e23f52302-lossType: squared,\n\tGBTRegressor_44f5a2b1652e23f52302-maxBins: 800,\n\tGBTRegressor_44f5a2b1652e23f52302-maxDepth: 5,\n\tGBTRegressor_44f5a2b1652e23f52302-maxIter: 5,\n\tGBTRegressor_44f5a2b1652e23f52302-maxMemoryInMB: 256,\n\tGBTRegressor_44f5a2b1652e23f52302-minInfoGain: 0.0,\n\tGBTRegressor_44f5a2b1652e23f52302-minInstancesPerNode: 1,\n\tGBTRegressor_44f5a2b1652e23f52302-predictionCol: prediction,\n\tGBTRegressor_44f5a2b1652e23f52302-seed: -6363326153609583521,\n\tGBTRegressor_44f5a2b1652e23f52302-stepSize: 0.1,\n\tGBTRegressor_44f5a2b1652e23f52302-subsamplingRate: 1.0\n}\n"}]},"apps":[],"jobName":"paragraph_1524848793788_1276365358","id":"20180427-080024_1308706169","dateCreated":"2018-04-27T17:06:33+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:176","user":"anonymous","dateFinished":"2018-04-28T02:20:33+0000","dateStarted":"2018-04-28T02:20:33+0000"},{"text":"%pyspark\n#Vemos los mejores parametros para RF\nprint(resultado[0].stages[-1]._java_obj.extractParamMap())","user":"anonymous","dateUpdated":"2018-04-28T02:27:57+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1524882348547_1682170052","id":"20180428-022548_484744165","dateCreated":"2018-04-28T02:25:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:29717","dateFinished":"2018-04-28T02:26:26+0000","dateStarted":"2018-04-28T02:26:26+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"{\n\tRandomForestRegressor_4d8f98d1f9210b258efd-cacheNodeIds: false,\n\tRandomForestRegressor_4d8f98d1f9210b258efd-checkpointInterval: 10,\n\tRandomForestRegressor_4d8f98d1f9210b258efd-featureSubsetStrategy: auto,\n\tRandomForestRegressor_4d8f98d1f9210b258efd-featuresCol: features,\n\tRandomForestRegressor_4d8f98d1f9210b258efd-impurity: variance,\n\tRandomForestRegressor_4d8f98d1f9210b258efd-labelCol: DEPARTURE_DELAY,\n\tRandomForestRegressor_4d8f98d1f9210b258efd-maxBins: 900,\n\tRandomForestRegressor_4d8f98d1f9210b258efd-maxDepth: 5,\n\tRandomForestRegressor_4d8f98d1f9210b258efd-maxMemoryInMB: 256,\n\tRandomForestRegressor_4d8f98d1f9210b258efd-minInfoGain: 0.0,\n\tRandomForestRegressor_4d8f98d1f9210b258efd-minInstancesPerNode: 1,\n\tRandomForestRegressor_4d8f98d1f9210b258efd-numTrees: 5,\n\tRandomForestRegressor_4d8f98d1f9210b258efd-predictionCol: prediction,\n\tRandomForestRegressor_4d8f98d1f9210b258efd-seed: -5851613654371098793,\n\tRandomForestRegressor_4d8f98d1f9210b258efd-subsamplingRate: 1.0\n}\n"}]}},{"text":"%pyspark\n#Vemos que método fue mejor comparando RMSE\ndf.orderBy(\"Modelo\", ascending=True).limit(2).show()","dateUpdated":"2018-04-28T02:30:04+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1524848793788_1276365358","id":"20180427-123144_144502968","dateCreated":"2018-04-27T17:06:33+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:177","user":"anonymous","dateFinished":"2018-04-28T02:19:16+0000","dateStarted":"2018-04-28T02:19:15+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------+------------------+\n|Modelo|              RMSE|\n+------+------------------+\n|    GB| 8.431378154849645|\n|    RF|14.662438802560672|\n+------+------------------+\n\n"}]}},{"text":"%pyspark\n","user":"anonymous","dateUpdated":"2018-04-28T02:19:15+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1524881955807_1273955281","id":"20180428-021915_1204500709","dateCreated":"2018-04-28T02:19:15+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:29584"}],"name":"Tarea_7","id":"2DDFXPWJU","angularObjects":{"2BRWU4WXC:shared_process":[],"2AM1YV5CU:shared_process":[],"2AJXGMUUJ:shared_process":[],"2ANGGHHMQ:shared_process":[],"2AKK3QQXU:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}