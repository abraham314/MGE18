{"paragraphs":[{"text":"%pyspark\nfrom pyspark.sql import SQLContext\nfrom pyspark.ml.feature import VectorIndexer\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.feature import StandardScaler\nfrom pyspark.ml.regression import DecisionTreeRegressor\nfrom pyspark.ml.regression import RandomForestRegressor\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml import Pipeline\nfrom timeit import default_timer as timer\n\nsqlContext = SQLContext(sc)\n\n# Leo la base flights.csv\nvuelos = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('s3a://aws-alex-03032018-metodos-gran-escala/datos/flights.csv')\n\n# Elimino aquellas variables que tienen datos \"NA\", con excepción de \"DEPARTURE_DELAY\" pues es la variable objetivo, por lo que en este caso pongo en ceros los registros para esta variable que tienen \"NA\".\n# Asimismo, selecciono las variables que sulten de interés para predecir la variable \"DEPARTURE_DELAY\" sin incrementar la dimensionalidad.\nvuelos_selec =vuelos.select('MONTH','DAY','DAY_OF_WEEK','FLIGHT_NUMBER','AIR_TIME','DISTANCE','DIVERTED','CANCELLED','DEPARTURE_DELAY').na.drop(subset='DEPARTURE_DELAY')\nvuelos_selec = vuelos_selec.na.fill(0)\n\n# Hago el VectorAssembler para definir los features.\nvec_ass = VectorAssembler(inputCols=['MONTH','DAY','DAY_OF_WEEK','FLIGHT_NUMBER','AIR_TIME','DISTANCE','DIVERTED','CANCELLED'],outputCol='features')\n\n# Estandarizo las variables.\nstd_scaler = StandardScaler(inputCol='features', outputCol='scaled_features')\n\n# Defino un \"Decision tree regression\" que reciba los features ya estandarizados.\ndtr = DecisionTreeRegressor(featuresCol='scaled_features',labelCol='DEPARTURE_DELAY')\n\n# Defino un \"Random forest regression\" que reciba los features ya estandarizados.\nrfr = RandomForestRegressor(featuresCol='scaled_features',labelCol='DEPARTURE_DELAY')\n\n# Defino los pipelines de los dos modelos a utilizar.\npipeline = {}\nparamGrid = {}\npipeline['dtr'] = Pipeline(stages=[vec_ass,std_scaler,dtr])\npipeline['rfr'] = Pipeline(stages=[vec_ass,std_scaler,rfr])\n\n# Defino los Grid sobre el cual van a probar parámetros para ambos modelos.\nparamGrid['dtr'] = ParamGridBuilder() \\\n    .addGrid(dtr.maxBins, [5, 10, 15]) \\\n    .addGrid(dtr.minInstancesPerNode, [2, 5, 10]) \\\n    .build()\n\nparamGrid['rfr'] = ParamGridBuilder() \\\n    .addGrid(rfr.maxDepth, [2, 5, 7]) \\\n    .addGrid(rfr.numTrees, [5, 8, 10]) \\\n    .build()\n\n\n# Defino el evaluador con la metrica rmse.\neval = RegressionEvaluator(metricName='rmse', predictionCol='prediction', labelCol=\"DEPARTURE_DELAY\")\n\n# Divido la base en 70% entrenamiento y 30% prueba.\n(entrena,prueba) = vuelos_selec.randomSplit([0.7,0.3])\n\nstart = timer()\n\nfor mod in pipeline:\n    # Realizo vallidación cruzada utilizando 10 folds como se indica en las notas.\n    crossval = CrossValidator(estimator=pipeline[mod],\n                          estimatorParamMaps=paramGrid[mod],\n                          evaluator=eval,\n                          numFolds=10)\n    # Entreno el modelo con los datos de entrenamiento.\n    cv_modelo = crossval.fit(entrena)\n\n    # Hago las predicciones.\n    predicciones = cv_modelo.transform(prueba)\n\n    # Imprimo el modelo, el mejor modelo y el rmse.\n    print(\"Modelo: \" + mod)\n    mejor_pipeline = cv_modelo.bestModel\n    mejor_modelo = mejor_pipeline.stages[2]\n    print(\"El mejor modelo es es: \",mejor_modelo)\n    print(\"------------\")\n    print(\"Parametros:\")\n    print(mejor_modelo.extractParamMap())\n    rmse = eval.evaluate(predicciones)\n    print(\"------------\")\n    print(\"El rmse es: \" ,rmse)\n    print(\"------------\")\n    print(\"------------\")\n    print(\"------------\")\n\nend = timer()\nprint(\"Tiempo de ejecución del Magic Loop:\", end - start)","user":"anonymous","dateUpdated":"2018-04-24T11:37:03+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Modelo: dtr\n('El mejor modelo es es: ', DecisionTreeRegressionModel (uid=DecisionTreeRegressor_4660b4b387395df96002) of depth 5 with 63 nodes)\n------------\nParametros:\n{Param(parent=u'DecisionTreeRegressor_4660b4b387395df96002', name='cacheNodeIds', doc='If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees.'): False, Param(parent=u'DecisionTreeRegressor_4660b4b387395df96002', name='maxMemoryInMB', doc='Maximum memory in MB allocated to histogram aggregation.'): 256, Param(parent=u'DecisionTreeRegressor_4660b4b387395df96002', name='checkpointInterval', doc='set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext'): 10, Param(parent=u'DecisionTreeRegressor_4660b4b387395df96002', name='featuresCol', doc='features column name'): 'scaled_features', Param(parent=u'DecisionTreeRegressor_4660b4b387395df96002', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent=u'DecisionTreeRegressor_4660b4b387395df96002', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 10, Param(parent=u'DecisionTreeRegressor_4660b4b387395df96002', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0, Param(parent=u'DecisionTreeRegressor_4660b4b387395df96002', name='labelCol', doc='label column name'): 'DEPARTURE_DELAY', Param(parent=u'DecisionTreeRegressor_4660b4b387395df96002', name='seed', doc='random seed'): -2808853809871465425, Param(parent=u'DecisionTreeRegressor_4660b4b387395df96002', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: variance'): 'variance', Param(parent=u'DecisionTreeRegressor_4660b4b387395df96002', name='predictionCol', doc='prediction column name'): 'prediction', Param(parent=u'DecisionTreeRegressor_4660b4b387395df96002', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split.  If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 10}\n------------\n('El rmse es: ', 36.96310051673188)\n------------\n------------\n------------\nModelo: rfr\n('El mejor modelo es es: ', RandomForestRegressionModel (uid=RandomForestRegressor_4735ba203015cf781eda) with 5 trees)\n------------\nParametros:\n{Param(parent=u'RandomForestRegressor_4735ba203015cf781eda', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 7, Param(parent=u'RandomForestRegressor_4735ba203015cf781eda', name='labelCol', doc='label column name'): 'DEPARTURE_DELAY', Param(parent=u'RandomForestRegressor_4735ba203015cf781eda', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32, Param(parent=u'RandomForestRegressor_4735ba203015cf781eda', name='predictionCol', doc='prediction column name'): 'prediction', Param(parent=u'RandomForestRegressor_4735ba203015cf781eda', name='seed', doc='random seed'): -5851613654371098793, Param(parent=u'RandomForestRegressor_4735ba203015cf781eda', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0, Param(parent=u'RandomForestRegressor_4735ba203015cf781eda', name='featuresCol', doc='features column name'): 'scaled_features', Param(parent=u'RandomForestRegressor_4735ba203015cf781eda', name='numTrees', doc='Number of trees to train (>= 1)'): 5, Param(parent=u'RandomForestRegressor_4735ba203015cf781eda', name='featureSubsetStrategy', doc='The number of features to consider for splits at each tree node. Supported options: auto, all, onethird, sqrt, log2, (0.0-1.0], [1-n].'): 'auto', Param(parent=u'RandomForestRegressor_4735ba203015cf781eda', name='checkpointInterval', doc='set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext'): 10, Param(parent=u'RandomForestRegressor_4735ba203015cf781eda', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split.  If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent=u'RandomForestRegressor_4735ba203015cf781eda', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: variance'): 'variance', Param(parent=u'RandomForestRegressor_4735ba203015cf781eda', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0, Param(parent=u'RandomForestRegressor_4735ba203015cf781eda', name='cacheNodeIds', doc='If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees.'): False, Param(parent=u'RandomForestRegressor_4735ba203015cf781eda', name='maxMemoryInMB', doc='Maximum memory in MB allocated to histogram aggregation.'): 256}\n------------\n('El rmse es: ', 36.87540390538917)\n------------\n------------\n------------\n('Tiempo de ejecuci\\xc3\\xb3n del Magic Loop:', 3379.79599404335)\n"}]},"apps":[],"jobName":"paragraph_1524567716744_-1872488165","id":"20180424-110156_1761964942","dateCreated":"2018-04-24T11:01:56+0000","dateStarted":"2018-04-24T11:37:03+0000","dateFinished":"2018-04-24T12:33:49+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1845"},{"text":"%pyspark\n","user":"anonymous","dateUpdated":"2018-04-24T11:18:05+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1524568685299_-1687612767","id":"20180424-111805_276084261","dateCreated":"2018-04-24T11:18:05+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:1846"}],"name":"tarea7","id":"2DBUAXKSJ","angularObjects":{"2BRWU4WXC:shared_process":[],"2AM1YV5CU:shared_process":[],"2AJXGMUUJ:shared_process":[],"2ANGGHHMQ:shared_process":[],"2AKK3QQXU:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}