{"nbformat_minor": 2, "nbformat": 4, "cells": [{"source": "## Using Spark's ML library for Machine Learning\n\nThrough this project, I will guide you around the use of Apache Spark's Machine Learning library. In this exercise, we'll be working with the 'flights' database, which contains information on flights in the US including departure and arrival airport, delays information, airline, among others.  \n\nOur objective will be to predict a flight's departure delay with available data. To do this, we will use different models, tuned through a Parameter map with which we can try different parameter values and finally run through a 'Magic Loop' to try both of them out. Feature engineering, if required, will be done with a Pipeline object.\n\nDataset used may be downloaded from [here](https://www.kaggle.com/usdot/flight-delays)  \nA glossary for the variables can be found [here](https://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236&DB_Short_Name=On-Time)", "cell_type": "markdown", "metadata": {}}, {"source": "### Creating a Spark Session\nIn this project I scripted the code to test its proper functionality on my computer, using [jupyter's pyspark docker image](https://hub.docker.com/r/jupyter/all-spark-notebook/). After running all of my code locally and making sure there weren't any errors, I created a cluster on AWS' EMR with 4 r4.large instances which have 4 cores and 30 GBs RAM each. I also changed the following settings to Spark:  \n\nspark.executor.memory            20G  \nspark.executor.cores             4  \nspark.driver.memory              20G  \n\nThe following script is as was run on the AWS cluster:", "cell_type": "markdown", "metadata": {}}, {"source": "# Added libraries.\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import DoubleType\nfrom pyspark.sql.window import Window\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml import Transformer\nfrom pyspark.ml.feature import StringIndexer, OneHotEncoder, Bucketizer, RFormula\nimport pandas as pd\nimport numpy as np\nimport time\npd.set_option('display.max_columns', 40)\n\n# The following scripts are to start a SparkSession on local mode\n#spark = SparkSession.builder.master(\"local[*]\")\\\n#.config(\"spark.executor.memory\", \"10G\")\\\n#.config(\"spark.driver.memory\", \"10G\")\\\n#.config(\"spark.memory.fraction\", \".8\")\\\n#.getOrCreate()\n# Using * within the box in local means we grant Spark access to all threads on our computer, this may be changed.", "cell_type": "code", "execution_count": 1, "outputs": [], "metadata": {"trusted": true}}, {"source": "### Exploratory Analysis\nAfter this, we'll load the database into Spark and we'll take a first look at what we have:", "cell_type": "markdown", "metadata": {}}, {"source": "flights = spark.read.csv('s3://daniel-sharp/datos/flights/flights.csv', header =True) \n# read.csv has an argument 'inferSchema' which will try to parse columns to their 'appropiate' type. However,\n# here we avoid it as it produces unwanted results, such as parsing time \"0005\" to 5, which means we lose information\n# As it is, it will parse all columns to type 'string'", "cell_type": "code", "execution_count": 2, "outputs": [], "metadata": {"trusted": true}}, {"source": "First, we will take a look at what data we have:", "cell_type": "markdown", "metadata": {}}, {"source": "num_rows = flights.count()\nnum_rows", "cell_type": "code", "execution_count": 3, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "5819079"}, "execution_count": 3}], "metadata": {"trusted": true}}, {"source": "So we have information from 5,819,079 flights.\n\nNext, we will look at our data and check if we need to make any changes:", "cell_type": "markdown", "metadata": {}}, {"source": "flights.limit(10).toPandas()", "cell_type": "code", "execution_count": 4, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>YEAR</th>\n      <th>MONTH</th>\n      <th>DAY</th>\n      <th>DAY_OF_WEEK</th>\n      <th>AIRLINE</th>\n      <th>FLIGHT_NUMBER</th>\n      <th>TAIL_NUMBER</th>\n      <th>ORIGIN_AIRPORT</th>\n      <th>DESTINATION_AIRPORT</th>\n      <th>SCHEDULED_DEPARTURE</th>\n      <th>DEPARTURE_TIME</th>\n      <th>DEPARTURE_DELAY</th>\n      <th>TAXI_OUT</th>\n      <th>WHEELS_OFF</th>\n      <th>SCHEDULED_TIME</th>\n      <th>ELAPSED_TIME</th>\n      <th>AIR_TIME</th>\n      <th>DISTANCE</th>\n      <th>WHEELS_ON</th>\n      <th>TAXI_IN</th>\n      <th>SCHEDULED_ARRIVAL</th>\n      <th>ARRIVAL_TIME</th>\n      <th>ARRIVAL_DELAY</th>\n      <th>DIVERTED</th>\n      <th>CANCELLED</th>\n      <th>CANCELLATION_REASON</th>\n      <th>AIR_SYSTEM_DELAY</th>\n      <th>SECURITY_DELAY</th>\n      <th>AIRLINE_DELAY</th>\n      <th>LATE_AIRCRAFT_DELAY</th>\n      <th>WEATHER_DELAY</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2015</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>AS</td>\n      <td>98</td>\n      <td>N407AS</td>\n      <td>ANC</td>\n      <td>SEA</td>\n      <td>0005</td>\n      <td>2354</td>\n      <td>-11</td>\n      <td>21</td>\n      <td>0015</td>\n      <td>205</td>\n      <td>194</td>\n      <td>169</td>\n      <td>1448</td>\n      <td>0404</td>\n      <td>4</td>\n      <td>0430</td>\n      <td>0408</td>\n      <td>-22</td>\n      <td>0</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2015</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>AA</td>\n      <td>2336</td>\n      <td>N3KUAA</td>\n      <td>LAX</td>\n      <td>PBI</td>\n      <td>0010</td>\n      <td>0002</td>\n      <td>-8</td>\n      <td>12</td>\n      <td>0014</td>\n      <td>280</td>\n      <td>279</td>\n      <td>263</td>\n      <td>2330</td>\n      <td>0737</td>\n      <td>4</td>\n      <td>0750</td>\n      <td>0741</td>\n      <td>-9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2015</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>US</td>\n      <td>840</td>\n      <td>N171US</td>\n      <td>SFO</td>\n      <td>CLT</td>\n      <td>0020</td>\n      <td>0018</td>\n      <td>-2</td>\n      <td>16</td>\n      <td>0034</td>\n      <td>286</td>\n      <td>293</td>\n      <td>266</td>\n      <td>2296</td>\n      <td>0800</td>\n      <td>11</td>\n      <td>0806</td>\n      <td>0811</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2015</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>AA</td>\n      <td>258</td>\n      <td>N3HYAA</td>\n      <td>LAX</td>\n      <td>MIA</td>\n      <td>0020</td>\n      <td>0015</td>\n      <td>-5</td>\n      <td>15</td>\n      <td>0030</td>\n      <td>285</td>\n      <td>281</td>\n      <td>258</td>\n      <td>2342</td>\n      <td>0748</td>\n      <td>8</td>\n      <td>0805</td>\n      <td>0756</td>\n      <td>-9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2015</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>AS</td>\n      <td>135</td>\n      <td>N527AS</td>\n      <td>SEA</td>\n      <td>ANC</td>\n      <td>0025</td>\n      <td>0024</td>\n      <td>-1</td>\n      <td>11</td>\n      <td>0035</td>\n      <td>235</td>\n      <td>215</td>\n      <td>199</td>\n      <td>1448</td>\n      <td>0254</td>\n      <td>5</td>\n      <td>0320</td>\n      <td>0259</td>\n      <td>-21</td>\n      <td>0</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2015</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>DL</td>\n      <td>806</td>\n      <td>N3730B</td>\n      <td>SFO</td>\n      <td>MSP</td>\n      <td>0025</td>\n      <td>0020</td>\n      <td>-5</td>\n      <td>18</td>\n      <td>0038</td>\n      <td>217</td>\n      <td>230</td>\n      <td>206</td>\n      <td>1589</td>\n      <td>0604</td>\n      <td>6</td>\n      <td>0602</td>\n      <td>0610</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2015</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>NK</td>\n      <td>612</td>\n      <td>N635NK</td>\n      <td>LAS</td>\n      <td>MSP</td>\n      <td>0025</td>\n      <td>0019</td>\n      <td>-6</td>\n      <td>11</td>\n      <td>0030</td>\n      <td>181</td>\n      <td>170</td>\n      <td>154</td>\n      <td>1299</td>\n      <td>0504</td>\n      <td>5</td>\n      <td>0526</td>\n      <td>0509</td>\n      <td>-17</td>\n      <td>0</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2015</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>US</td>\n      <td>2013</td>\n      <td>N584UW</td>\n      <td>LAX</td>\n      <td>CLT</td>\n      <td>0030</td>\n      <td>0044</td>\n      <td>14</td>\n      <td>13</td>\n      <td>0057</td>\n      <td>273</td>\n      <td>249</td>\n      <td>228</td>\n      <td>2125</td>\n      <td>0745</td>\n      <td>8</td>\n      <td>0803</td>\n      <td>0753</td>\n      <td>-10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2015</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>AA</td>\n      <td>1112</td>\n      <td>N3LAAA</td>\n      <td>SFO</td>\n      <td>DFW</td>\n      <td>0030</td>\n      <td>0019</td>\n      <td>-11</td>\n      <td>17</td>\n      <td>0036</td>\n      <td>195</td>\n      <td>193</td>\n      <td>173</td>\n      <td>1464</td>\n      <td>0529</td>\n      <td>3</td>\n      <td>0545</td>\n      <td>0532</td>\n      <td>-13</td>\n      <td>0</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2015</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>DL</td>\n      <td>1173</td>\n      <td>N826DN</td>\n      <td>LAS</td>\n      <td>ATL</td>\n      <td>0030</td>\n      <td>0033</td>\n      <td>3</td>\n      <td>12</td>\n      <td>0045</td>\n      <td>221</td>\n      <td>203</td>\n      <td>186</td>\n      <td>1747</td>\n      <td>0651</td>\n      <td>5</td>\n      <td>0711</td>\n      <td>0656</td>\n      <td>-15</td>\n      <td>0</td>\n      <td>0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   YEAR MONTH DAY DAY_OF_WEEK AIRLINE FLIGHT_NUMBER TAIL_NUMBER  \\\n0  2015     1   1           4      AS            98      N407AS   \n1  2015     1   1           4      AA          2336      N3KUAA   \n2  2015     1   1           4      US           840      N171US   \n3  2015     1   1           4      AA           258      N3HYAA   \n4  2015     1   1           4      AS           135      N527AS   \n5  2015     1   1           4      DL           806      N3730B   \n6  2015     1   1           4      NK           612      N635NK   \n7  2015     1   1           4      US          2013      N584UW   \n8  2015     1   1           4      AA          1112      N3LAAA   \n9  2015     1   1           4      DL          1173      N826DN   \n\n  ORIGIN_AIRPORT DESTINATION_AIRPORT SCHEDULED_DEPARTURE DEPARTURE_TIME  \\\n0            ANC                 SEA                0005           2354   \n1            LAX                 PBI                0010           0002   \n2            SFO                 CLT                0020           0018   \n3            LAX                 MIA                0020           0015   \n4            SEA                 ANC                0025           0024   \n5            SFO                 MSP                0025           0020   \n6            LAS                 MSP                0025           0019   \n7            LAX                 CLT                0030           0044   \n8            SFO                 DFW                0030           0019   \n9            LAS                 ATL                0030           0033   \n\n  DEPARTURE_DELAY TAXI_OUT WHEELS_OFF SCHEDULED_TIME ELAPSED_TIME AIR_TIME  \\\n0             -11       21       0015            205          194      169   \n1              -8       12       0014            280          279      263   \n2              -2       16       0034            286          293      266   \n3              -5       15       0030            285          281      258   \n4              -1       11       0035            235          215      199   \n5              -5       18       0038            217          230      206   \n6              -6       11       0030            181          170      154   \n7              14       13       0057            273          249      228   \n8             -11       17       0036            195          193      173   \n9               3       12       0045            221          203      186   \n\n  DISTANCE WHEELS_ON TAXI_IN SCHEDULED_ARRIVAL ARRIVAL_TIME ARRIVAL_DELAY  \\\n0     1448      0404       4              0430         0408           -22   \n1     2330      0737       4              0750         0741            -9   \n2     2296      0800      11              0806         0811             5   \n3     2342      0748       8              0805         0756            -9   \n4     1448      0254       5              0320         0259           -21   \n5     1589      0604       6              0602         0610             8   \n6     1299      0504       5              0526         0509           -17   \n7     2125      0745       8              0803         0753           -10   \n8     1464      0529       3              0545         0532           -13   \n9     1747      0651       5              0711         0656           -15   \n\n  DIVERTED CANCELLED CANCELLATION_REASON AIR_SYSTEM_DELAY SECURITY_DELAY  \\\n0        0         0                None             None           None   \n1        0         0                None             None           None   \n2        0         0                None             None           None   \n3        0         0                None             None           None   \n4        0         0                None             None           None   \n5        0         0                None             None           None   \n6        0         0                None             None           None   \n7        0         0                None             None           None   \n8        0         0                None             None           None   \n9        0         0                None             None           None   \n\n  AIRLINE_DELAY LATE_AIRCRAFT_DELAY WEATHER_DELAY  \n0          None                None          None  \n1          None                None          None  \n2          None                None          None  \n3          None                None          None  \n4          None                None          None  \n5          None                None          None  \n6          None                None          None  \n7          None                None          None  \n8          None                None          None  \n9          None                None          None  "}, "execution_count": 4}], "metadata": {"trusted": true}}, {"source": "# Check for null values, with guidance from:\n# https://stackoverflow.com/questions/44627386/how-to-find-count-of-null-and-nan-values-for-each-column-in-a-pyspark-dataframe\nflights.select([(count(when(isnan(c) | col(c).isNull(), c))/num_rows).alias(c) for c in flights.columns]).toPandas()", "cell_type": "code", "execution_count": 5, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>YEAR</th>\n      <th>MONTH</th>\n      <th>DAY</th>\n      <th>DAY_OF_WEEK</th>\n      <th>AIRLINE</th>\n      <th>FLIGHT_NUMBER</th>\n      <th>TAIL_NUMBER</th>\n      <th>ORIGIN_AIRPORT</th>\n      <th>DESTINATION_AIRPORT</th>\n      <th>SCHEDULED_DEPARTURE</th>\n      <th>DEPARTURE_TIME</th>\n      <th>DEPARTURE_DELAY</th>\n      <th>TAXI_OUT</th>\n      <th>WHEELS_OFF</th>\n      <th>SCHEDULED_TIME</th>\n      <th>ELAPSED_TIME</th>\n      <th>AIR_TIME</th>\n      <th>DISTANCE</th>\n      <th>WHEELS_ON</th>\n      <th>TAXI_IN</th>\n      <th>SCHEDULED_ARRIVAL</th>\n      <th>ARRIVAL_TIME</th>\n      <th>ARRIVAL_DELAY</th>\n      <th>DIVERTED</th>\n      <th>CANCELLED</th>\n      <th>CANCELLATION_REASON</th>\n      <th>AIR_SYSTEM_DELAY</th>\n      <th>SECURITY_DELAY</th>\n      <th>AIRLINE_DELAY</th>\n      <th>LATE_AIRCRAFT_DELAY</th>\n      <th>WEATHER_DELAY</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00253</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.014805</td>\n      <td>0.014805</td>\n      <td>0.015303</td>\n      <td>0.015303</td>\n      <td>0.000001</td>\n      <td>0.018056</td>\n      <td>0.018056</td>\n      <td>0.0</td>\n      <td>0.015898</td>\n      <td>0.015898</td>\n      <td>0.0</td>\n      <td>0.015898</td>\n      <td>0.018056</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.984554</td>\n      <td>0.81725</td>\n      <td>0.81725</td>\n      <td>0.81725</td>\n      <td>0.81725</td>\n      <td>0.81725</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   YEAR  MONTH  DAY  DAY_OF_WEEK  AIRLINE  FLIGHT_NUMBER  TAIL_NUMBER  \\\n0   0.0    0.0  0.0          0.0      0.0            0.0      0.00253   \n\n   ORIGIN_AIRPORT  DESTINATION_AIRPORT  SCHEDULED_DEPARTURE  DEPARTURE_TIME  \\\n0             0.0                  0.0                  0.0        0.014805   \n\n   DEPARTURE_DELAY  TAXI_OUT  WHEELS_OFF  SCHEDULED_TIME  ELAPSED_TIME  \\\n0         0.014805  0.015303    0.015303        0.000001      0.018056   \n\n   AIR_TIME  DISTANCE  WHEELS_ON   TAXI_IN  SCHEDULED_ARRIVAL  ARRIVAL_TIME  \\\n0  0.018056       0.0   0.015898  0.015898                0.0      0.015898   \n\n   ARRIVAL_DELAY  DIVERTED  CANCELLED  CANCELLATION_REASON  AIR_SYSTEM_DELAY  \\\n0       0.018056       0.0        0.0             0.984554           0.81725   \n\n   SECURITY_DELAY  AIRLINE_DELAY  LATE_AIRCRAFT_DELAY  WEATHER_DELAY  \n0         0.81725        0.81725              0.81725        0.81725  "}, "execution_count": 5}], "metadata": {"trusted": true}}, {"source": "flights.withColumn(\"delay\", flights[\"DEPARTURE_DELAY\"].cast(DoubleType())).describe(\"delay\").show()", "cell_type": "code", "execution_count": 6, "outputs": [{"output_type": "stream", "name": "stdout", "text": "+-------+------------------+\n|summary|             delay|\n+-------+------------------+\n|  count|           5732926|\n|   mean| 9.370158275198389|\n| stddev|37.080942496786925|\n|    min|             -82.0|\n|    max|            1988.0|\n+-------+------------------+\n\n"}], "metadata": {"trusted": true}}, {"source": "### Data Cleaning and Feature Engineering\n\nFrom the latter, we know the following changes can be made:\n- Parse to integer:\n    + Departure Delay (our response variable)\n    + Distance\n    + Arrival delay\n    + Scheduled time\n    + Month\n    + Day of the week\n    + Day\n \n- Parse to time - where I will extract the hour  \n   + Scheduled Departure\n   + Departure time\n   + Scheduled arrival\n   + Arrival time\n   + Scheduled Arrival  \n   \n- Columns to delete - too many missing values -\n    + Cancellation Reason\n    + Air System Delay\n    + Security Delay\n    + Airline Delay\n    + Late Aircraft Delay\n    + Weather Delay\n    + Year (we know all our data is from 2015, so this column has no variance and thus is useless)  \n    \n- Doubtful variables - may be redundant to other information (high correlation) & data leakage - \n    + Taxi in\n    + Taxi out\n    + Air time\n    + Wheels on\n    + Wheels off   \n    + Air time\n    + Diverted\n    + Cancelled\n    + Elapsed time\n    \nI will also remove all remaining rows with Null values, which will represent 1.8% of the data at the most, which is insignificant.  \n\nIt is also important to consider that some of these variables may produce **'data leakage'** as they could only be known after or along with the fact, for example: DEPARTURE_TIME, WHEELS_OFF, among others. We need to remove these variables for the same flight. \n\n**Since we want to fit all these steps in a pipeline, we need to creates a series of classes that have a transform method within them. These are outlined next:**\n", "cell_type": "markdown", "metadata": {}}, {"source": "# To parse strings into integers\nclass ParserDouble(Transformer):  \n\n    def __init__(self, columns=[None]):\n        self.columns = columns\n\n    def _transform(self, df):\n        for col in self.columns:\n            df = df.withColumn(col, df[col].cast(DoubleType()))\n        self = df\n        return self", "cell_type": "code", "execution_count": 7, "outputs": [], "metadata": {"trusted": true}}, {"source": "# To separate time into hours + minutes\nclass getHour(Transformer):  \n\n    def __init__(self, columns=[None]):\n        self.columns = columns\n\n    def _transform(self, df):\n        for col in self.columns:\n            df = df.withColumn(col+\"_HOUR\", substring(col,0,2))\n        self = df\n        return self", "cell_type": "code", "execution_count": 8, "outputs": [], "metadata": {"trusted": true}}, {"source": "# To remove unwanted columns\nclass rm_cols(Transformer):  \n\n    def __init__(self, columns=[None]):\n        self.columns = columns\n\n    def _transform(self, df):\n        for col in self.columns:\n            df = df.drop(col)\n        self = df\n        return self", "cell_type": "code", "execution_count": 9, "outputs": [], "metadata": {"trusted": true}}, {"source": "# To remove rows with Null values\nclass rm_nulls(Transformer):  \n    def _transform(self, df):\n        self = df.na.drop(how=\"any\")\n        return self", "cell_type": "code", "execution_count": 10, "outputs": [], "metadata": {"trusted": true}}, {"source": "**Feature Engineering**  \n\nIt's important to note some variables aren't relevant for out prediction, such as those that happened after flight departure, eg. Arrival time at destination for flight of interest. However, this same variable might be relevant for our same flight's arrival previous to its departure time. We might be even interested in generating a 'time at airport' variable, which considers the time from landing to departure. We can do this by lagging rows for every flight tail number. This way we can 'track' the specific airplanes.  \n\nAlso, having categorical values such as Day and Time make our model much more complex as we would have to calculate n-1 parameters for each one. To avoid this, I will 'Bucketize' these columns into weeks and periods respectively. This way we can have week 1, week 2, week 3 and week 4 instead of days 1-31. This means our models will calculate 3 parameters instead of 30. The case for hours is analogous, I grouped the time variable into period of 4 hours each.  Unfortunately, doing this same exercise for the Aiports or Airlines variables is not possible. Maybe they could be categorized by cost-levels (maybe expecting cheaper airlines to be late more often), but I do not have that knowledge now. Airports could probably be categorized by regions, where maybe regions with more extreme weather face more delays.   \n  \nWe work on this next: ", "cell_type": "markdown", "metadata": {}}, {"source": "# Lag relevant columns from previous flights\nclass lagger(Transformer):  \n\n    def __init__(self, columns=[None], grouper = \"TAIL_NUMBER\"):\n        self.columns = columns\n        self.grouper = grouper\n        \n    def _transform(self, df):\n        for col in self.columns:\n            df = df.withColumn(col+\"_PREV\",lag(flights[col])\n                                 .over(Window.partitionBy(self.grouper).orderBy(self.grouper)))\n        self = df\n        return self", "cell_type": "code", "execution_count": 11, "outputs": [], "metadata": {"trusted": true}}, {"source": "# Create column with time difference between events\nclass t_diff(Transformer):  \n    def __init__(self, col_name = None, columns=[None]):\n        self.columns = columns\n        self.col_name = col_name\n    def _transform(self, df):\n        self = df.withColumn(self.col_name, when(df[\"DAY_OF_WEEK\"] > df[\"DAY_OF_WEEK_PREV\"], \n                                                2400 + df[self.columns[0]] - df[self.columns[1]]).\n                             otherwise(df[self.columns[0]] - df[self.columns[1]]))\n        #self = df.withColumn(self.col_name, df[self.columns[0]] - df[self.columns[1]])\n        return self", "cell_type": "code", "execution_count": 12, "outputs": [], "metadata": {"trusted": true}}, {"source": "Afterwards, we configure all the steps that will be used in out pipeline, which include removing columns with high number of null values and those that represent data leakage, lagging variables to get information on the airplanes previous flight and creating new variables, such as the time at airport variable. Finally, for use in our models, we have to 'One Hot Encode' our categorical variables.", "cell_type": "markdown", "metadata": {}}, {"source": "# Remove columns with significantly high NAs\nrm_cols_nas = rm_cols([\"CANCELLATION_REASON\",\"AIR_SYSTEM_DELAY\",\"SECURITY_DELAY\",\"AIRLINE_DELAY\",\"LATE_AIRCRAFT_DELAY\",\n                    \"WEATHER_DELAY\"])\n\n# Remove columns not useful to analysis or that present data leakage risk\nrm_cols_unnecessary = rm_cols([\"WHEELS_OFF\", \"TAXI_OUT\", \"CANCELLED\", \"DIVERTED\", \"WHEELS_ON\",\n                              \"AIR_TIME\", \"TAXI_IN\", \"YEAR\", \"ELAPSED_TIME\", \"SCHEDULED_TIME\", \"AIR_TIME\"])\n\n# Remove rows with null values\nrm_nulls1 = rm_nulls()\n\n# Lag columns from the flights previous trip (its grouped by TAIL_NUMBER)\nlagger1 = lagger(columns = [\"SCHEDULED_ARRIVAL\", \"DEPARTURE_TIME\", \"DEPARTURE_DELAY\", \"ARRIVAL_DELAY\",\n                           \"DAY_OF_WEEK\"], grouper = \"TAIL_NUMBER\")\n\n# Remove columns not useful to analysis or that present data leakage risk\nrm_cols_leakage= rm_cols([\"SCHEDULED_ARRIVAL\", \"ARRIVAL_TIME\", \"ARRIVAL_DELAY\", \"DEPARTURE_TIME\"])\n\n# Convert to integer\ndouble_maker = ParserDouble([\"DEPARTURE_DELAY\", \"DISTANCE\", \"ARRIVAL_DELAY_PREV\"])\n\n# Create time at airport variable (it doesn't really produce a time value as such, but represents a time 'proxy')\nt_at_airport = t_diff(col_name = \"SCHEDULED_TIME_AT_AIRPORT\", columns = [\"SCHEDULED_DEPARTURE\",\"SCHEDULED_ARRIVAL_PREV\"])\n\n# Separate time columns into hour-minute columns\nh_m_sep = getHour([\"SCHEDULED_DEPARTURE\"])\n\n# Final parse of strings to ints for relevant variables\ndouble_maker2 = ParserDouble([\"DEPARTURE_DELAY_PREV\",\"SCHEDULED_DEPARTURE_HOUR\", \"DAY\"])\n\n# Bucketize factor columns with many labels.\nbucketizer_day = Bucketizer(splits=[-float(\"inf\"), 7, 14, 21, float(\"inf\")], inputCol=\"DAY\", outputCol=\"WEEK\")\nbucketizer_time = Bucketizer(splits=[-float(\"inf\"), 4, 8, 12, 16, 20, float(\"inf\")], inputCol=\"SCHEDULED_DEPARTURE_HOUR\",\n                             outputCol=\"SCHED_DEPARTURE_PERIOD\")\n\n# Finally, we need to 'One-hot encode' our categorical variables for use in the models\ncat_vars = [\"AIRLINE\", \"ORIGIN_AIRPORT\", \"MONTH\", \"DAY_OF_WEEK\", \"WEEK\", \"SCHED_DEPARTURE_PERIOD\"]\n\nindexers = [StringIndexer(inputCol=column, outputCol=column+\"_INDEX\") for column in cat_vars ]\nhot_encoders = [OneHotEncoder(inputCol=column+\"_INDEX\", outputCol=column+\"_HOT\") for column in cat_vars ]\n\n# Remove all unnecessary variables remaining\nrm_rem= rm_cols([\"SCHEDULED_ARRIVAL_PREV\", \"SCHEDULED_DEPARTURE\", \"ARRIVAL_TIME_PREV\", \"DEPARTURE_TIME_PREV\", \n                 \"AIRLINE_INDEX\", 'TAIL_NUMBER','ORIGIN_AIRPORT_INDEX',\"AIRLINE\",'FLIGHT_NUMBER', 'TAIL_NUMBER',\n                 'ORIGIN_AIRPORT','DESTINATION_AIRPORT', \"DAY_OF_WEEK_PREV\", \"MONTH\", \"DAY\", \"DAY_OF_WEEK\",\n                 \"MONTH_INDEX\", \"WEEK_INDEX\",\"DAY_OF_WEEK_INDEX\", \"WEEK\", \"SCHEDULED_ARRIVAL_PREV\",\n                 \"SCHEDULED_DEPARTURE_HOUR\", \"SCHED_DEPARTURE_PERIOD_INDEX\", \"SCHED_DEPARTURE_PERIOD\"])", "cell_type": "code", "execution_count": 13, "outputs": [], "metadata": {"trusted": true}}, {"source": "data_prepare = Pipeline(stages = [rm_cols_nas, rm_cols_unnecessary, rm_nulls1, lagger1, rm_cols_leakage, double_maker, \n                                  rm_nulls1, t_at_airport, h_m_sep, double_maker2, bucketizer_day, bucketizer_time] + \n                        indexers + hot_encoders + [rm_rem])", "cell_type": "code", "execution_count": 14, "outputs": [], "metadata": {"trusted": true}}, {"source": "clean_flights = data_prepare.fit(flights).transform(flights)", "cell_type": "code", "execution_count": 15, "outputs": [], "metadata": {"trusted": true}}, {"source": "And now, our data is ready to be run through models!", "cell_type": "markdown", "metadata": {}}, {"source": "clean_flights.limit(10).toPandas()", "cell_type": "code", "execution_count": 16, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DEPARTURE_DELAY</th>\n      <th>DISTANCE</th>\n      <th>DEPARTURE_DELAY_PREV</th>\n      <th>ARRIVAL_DELAY_PREV</th>\n      <th>SCHEDULED_TIME_AT_AIRPORT</th>\n      <th>AIRLINE_HOT</th>\n      <th>ORIGIN_AIRPORT_HOT</th>\n      <th>MONTH_HOT</th>\n      <th>DAY_OF_WEEK_HOT</th>\n      <th>WEEK_HOT</th>\n      <th>SCHED_DEPARTURE_PERIOD_HOT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-3.0</td>\n      <td>500.0</td>\n      <td>75.0</td>\n      <td>72.0</td>\n      <td>1389.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 1.0, 0.0)</td>\n      <td>(0.0, 0.0, 0.0)</td>\n      <td>(1.0, 0.0, 0.0, 0.0, 0.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>46.0</td>\n      <td>130.0</td>\n      <td>-3.0</td>\n      <td>-7.0</td>\n      <td>1006.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 1.0, 0.0)</td>\n      <td>(0.0, 0.0, 0.0)</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 1.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-6.0</td>\n      <td>130.0</td>\n      <td>46.0</td>\n      <td>36.0</td>\n      <td>817.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>(0.0, 0.0, 1.0, 0.0, 0.0, 0.0)</td>\n      <td>(0.0, 0.0, 0.0)</td>\n      <td>(0.0, 0.0, 0.0, 1.0, 0.0)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-5.0</td>\n      <td>912.0</td>\n      <td>-6.0</td>\n      <td>-3.0</td>\n      <td>112.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>(0.0, 0.0, 1.0, 0.0, 0.0, 0.0)</td>\n      <td>(0.0, 0.0, 0.0)</td>\n      <td>(0.0, 0.0, 0.0, 1.0, 0.0)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-10.0</td>\n      <td>912.0</td>\n      <td>-5.0</td>\n      <td>2.0</td>\n      <td>86.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>(0.0, 0.0, 1.0, 0.0, 0.0, 0.0)</td>\n      <td>(0.0, 0.0, 0.0)</td>\n      <td>(1.0, 0.0, 0.0, 0.0, 0.0)</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>67.0</td>\n      <td>912.0</td>\n      <td>-10.0</td>\n      <td>-17.0</td>\n      <td>-30.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>(0.0, 0.0, 1.0, 0.0, 0.0, 0.0)</td>\n      <td>(0.0, 0.0, 0.0)</td>\n      <td>(0.0, 1.0, 0.0, 0.0, 0.0)</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>41.0</td>\n      <td>912.0</td>\n      <td>67.0</td>\n      <td>51.0</td>\n      <td>86.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>(0.0, 0.0, 1.0, 0.0, 0.0, 0.0)</td>\n      <td>(0.0, 0.0, 0.0)</td>\n      <td>(0.0, 1.0, 0.0, 0.0, 0.0)</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>6.0</td>\n      <td>366.0</td>\n      <td>41.0</td>\n      <td>26.0</td>\n      <td>59.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>(0.0, 0.0, 1.0, 0.0, 0.0, 0.0)</td>\n      <td>(0.0, 0.0, 0.0)</td>\n      <td>(0.0, 0.0, 1.0, 0.0, 0.0)</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.0</td>\n      <td>366.0</td>\n      <td>6.0</td>\n      <td>3.0</td>\n      <td>927.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0)</td>\n      <td>(0.0, 0.0, 0.0)</td>\n      <td>(0.0, 0.0, 0.0, 1.0, 0.0)</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>-6.0</td>\n      <td>130.0</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>104.0</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0)</td>\n      <td>(0.0, 0.0, 0.0)</td>\n      <td>(1.0, 0.0, 0.0, 0.0, 0.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   DEPARTURE_DELAY  DISTANCE  DEPARTURE_DELAY_PREV  ARRIVAL_DELAY_PREV  \\\n0             -3.0     500.0                  75.0                72.0   \n1             46.0     130.0                  -3.0                -7.0   \n2             -6.0     130.0                  46.0                36.0   \n3             -5.0     912.0                  -6.0                -3.0   \n4            -10.0     912.0                  -5.0                 2.0   \n5             67.0     912.0                 -10.0               -17.0   \n6             41.0     912.0                  67.0                51.0   \n7              6.0     366.0                  41.0                26.0   \n8              0.0     366.0                   6.0                 3.0   \n9             -6.0     130.0                   0.0                13.0   \n\n   SCHEDULED_TIME_AT_AIRPORT  \\\n0                     1389.0   \n1                     1006.0   \n2                      817.0   \n3                      112.0   \n4                       86.0   \n5                      -30.0   \n6                       86.0   \n7                       59.0   \n8                      927.0   \n9                      104.0   \n\n                                         AIRLINE_HOT  \\\n0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n3  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n4  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n5  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n6  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n7  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n8  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n9  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n\n                                  ORIGIN_AIRPORT_HOT  \\\n0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n3  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n4  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n5  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n6  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n7  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n8  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n9  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n\n                                           MONTH_HOT  \\\n0  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n1  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n2  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n3  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n4  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n5  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n6  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n7  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n8  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n9  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n\n                  DAY_OF_WEEK_HOT         WEEK_HOT SCHED_DEPARTURE_PERIOD_HOT  \n0  (0.0, 0.0, 0.0, 0.0, 1.0, 0.0)  (0.0, 0.0, 0.0)  (1.0, 0.0, 0.0, 0.0, 0.0)  \n1  (0.0, 0.0, 0.0, 0.0, 1.0, 0.0)  (0.0, 0.0, 0.0)  (0.0, 0.0, 0.0, 0.0, 1.0)  \n2  (0.0, 0.0, 1.0, 0.0, 0.0, 0.0)  (0.0, 0.0, 0.0)  (0.0, 0.0, 0.0, 1.0, 0.0)  \n3  (0.0, 0.0, 1.0, 0.0, 0.0, 0.0)  (0.0, 0.0, 0.0)  (0.0, 0.0, 0.0, 1.0, 0.0)  \n4  (0.0, 0.0, 1.0, 0.0, 0.0, 0.0)  (0.0, 0.0, 0.0)  (1.0, 0.0, 0.0, 0.0, 0.0)  \n5  (0.0, 0.0, 1.0, 0.0, 0.0, 0.0)  (0.0, 0.0, 0.0)  (0.0, 1.0, 0.0, 0.0, 0.0)  \n6  (0.0, 0.0, 1.0, 0.0, 0.0, 0.0)  (0.0, 0.0, 0.0)  (0.0, 1.0, 0.0, 0.0, 0.0)  \n7  (0.0, 0.0, 1.0, 0.0, 0.0, 0.0)  (0.0, 0.0, 0.0)  (0.0, 0.0, 1.0, 0.0, 0.0)  \n8  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0)  (0.0, 0.0, 0.0)  (0.0, 0.0, 0.0, 1.0, 0.0)  \n9  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0)  (0.0, 0.0, 0.0)  (1.0, 0.0, 0.0, 0.0, 0.0)  "}, "execution_count": 16}], "metadata": {"trusted": true}}, {"source": "And just to verify how much data we lost from Null values:", "cell_type": "markdown", "metadata": {}}, {"source": "(1 - clean_flights.count()/flights.count()) * 100", "cell_type": "code", "execution_count": 17, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "1.8897664046148899"}, "execution_count": 17}], "metadata": {"trusted": true}}, {"source": "We only lost ~1.9% of our data to null values.  ", "cell_type": "markdown", "metadata": {}}, {"source": "### Running models and tuning  \n\nAs stated at the beggining, our objetive is to find the best model to predict a flight's departure delay. This means we will try to predict a number and, thus, will need a regression model. In this case, we will work with two models: the standard Linear Regression Model and the Random Forest model.  \n\nTo start with, we have to divide our data in a training and a test sample, which we'll do 70% and 30% respectively. We can do a random split as we don't have sequential data to worry about", "cell_type": "markdown", "metadata": {}}, {"source": "(train_flights, test_flights) = clean_flights.randomSplit([0.70, 0.30])", "cell_type": "code", "execution_count": 18, "outputs": [], "metadata": {"trusted": true}}, {"source": "from pyspark.ml.regression import LinearRegression, RandomForestRegressor\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.param import Params", "cell_type": "code", "execution_count": 19, "outputs": [], "metadata": {"trusted": true}}, {"source": "Now we'll set up a 'magic loop' (so called by [Rayid Ghani](https://github.com/rayidghani) from Chicago's Data Science, Public Policy, Social Good Center for Data Science and Public Policy). The Magic Loop will iterate through our both models, running each one with different parameters, which we'll define with the ParamGridBuilder. In each model run we will use 10 fold cross validation and finally will evaluate the 'best model's' performance on the test sample.\n\nInstead of using 'for' loops for our Magic Loop, I adapted code from Bryan Cutler's [CV Pipelines](https://bryancutler.github.io/cv-pipelines/), which allows us to try diffferent models on a single CrossValidator object, which acts out as our Magic Loop. The benefit from doing this, is that our CrossValidator will run all the different models we give it and keep the best one.", "cell_type": "markdown", "metadata": {}}, {"source": "# Define the base characteristics of the models we will use:\nlr = LinearRegression(maxIter=10, featuresCol='features', labelCol='label')\nrf = RandomForestRegressor(subsamplingRate=0.15, featuresCol='features', labelCol='label')\n\n# Spark ML models require you input a 'label' column and a 'features' column.\n# To do this, we use vector assembler, which produces a 'features' column where each record is a vector of our covariates\nformula = RFormula(formula = \"DEPARTURE_DELAY ~ .\")\n#rm_extra = rm_cols(f_vars)\n# The following structure was adapted from https://bryancutler.github.io/cv-pipelines/\n\npipeline = Pipeline(stages=[formula])\n\nparamGrid_lr = ParamGridBuilder() \\\n    .baseOn({pipeline.stages: [formula, lr]}) \\\n    .addGrid(lr.elasticNetParam, [0.5, 1.0, 0.0]) \\\n    .addGrid(lr.regParam, [0.01, 0.001, 0.1])\\\n    .build()\n    \nparamGrid_rf = ParamGridBuilder() \\\n    .baseOn({pipeline.stages : [formula, rf]}) \\\n    .addGrid(rf.numTrees, [10, 20, 30]) \\\n    .addGrid(rf.featureSubsetStrategy, ['onethird', '0.5', 'sqrt'])\\\n    .build()\n    \nevaluator = RegressionEvaluator(metricName='rmse')\n\ngrids = paramGrid_rf + paramGrid_lr", "cell_type": "code", "execution_count": 20, "outputs": [], "metadata": {"trusted": true}}, {"source": "crossval = CrossValidator(estimatorParamMaps=grids,\n                          estimator=pipeline,\n                          evaluator=evaluator,\n                          numFolds=10,\n                         parallelism = 4)", "cell_type": "code", "execution_count": 21, "outputs": [], "metadata": {"trusted": true}}, {"source": "Here we fit out traning data to all our models. cvModel contains our best model along with other information from the Cross Validation runs:", "cell_type": "markdown", "metadata": {}}, {"source": "start_time = time.time()\ncvModel = crossval.fit(train_flights)\nend_time = time.time()", "cell_type": "code", "execution_count": 22, "outputs": [], "metadata": {"trusted": true}}, {"source": "print(\"--- Magic Loop execution: %s seconds ---\" % (end_time - start_time))", "cell_type": "code", "execution_count": 23, "outputs": [{"output_type": "stream", "name": "stdout", "text": "--- Magic Loop execution: 15658.50262594223 seconds ---\n"}], "metadata": {"trusted": true}}, {"source": "Running the Magic Loop on the EMR cluster took ~15,659 seconds, which is around 4.3 hours. This might sound like a long time, but we just trained 180 models ($3^2 = 9$ combinations per model, with 10 fold Cross Validation).\n\nSpark's objetive is more for production rather than for model exploration, which is why identifying model's performace isn't as easy as it is in Sci-kit learn, however, it can still be done.\n\nFollowing, we can see the average performance (RMSE) for each model during its k-fold runs, the metrics are shown in order of exectution, which means that the first half of values belong to the Random Forest model and the second half belong to our Linear Regression runs:", "cell_type": "markdown", "metadata": {}}, {"source": "cvModel.avgMetrics", "cell_type": "code", "execution_count": 24, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "[31.425270934910127,\n 30.845918655526823,\n 34.94443101990099,\n 31.398382173733125,\n 30.81426642031701,\n 34.85703232171853,\n 31.417874346423805,\n 30.83880871086108,\n 35.210848036877124,\n 33.69249481427418,\n 33.69268537951549,\n 33.695178433419564,\n 33.69562579280449,\n 33.70458705476841,\n 33.693430289161746,\n 33.703639429397434,\n 33.72220262933084,\n 33.6949916706693]"}, "execution_count": 24}], "metadata": {"trusted": true}}, {"source": "To obtain the best model we can use find the index of the element with the lowest value (in this case because its RMSE, but in others we might want to find the maximum), and extract its corresponding parameters. This only shows the best parameters as run by the CrossValidors, the rest of the model's parameters are either at default values, or as defined when the models are declared.\n\n#### Best Model", "cell_type": "markdown", "metadata": {}}, {"source": "cvModel.getEstimatorParamMaps()[ np.argmin(cvModel.avgMetrics) ]", "cell_type": "code", "execution_count": 25, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "{Param(parent='Pipeline_4d63958e14f5e691468e', name='stages', doc='a list of pipeline stages'): [RFormula_42c8b8393de389d8b760,\n  RandomForestRegressor_483f833d74c3e990ce8d],\n Param(parent='RandomForestRegressor_483f833d74c3e990ce8d', name='featureSubsetStrategy', doc='The number of features to consider for splits at each tree node. Supported options: auto, all, onethird, sqrt, log2, (0.0-1.0], [1-n].'): '0.5',\n Param(parent='RandomForestRegressor_483f833d74c3e990ce8d', name='numTrees', doc='Number of trees to train (>= 1).'): 20}"}, "execution_count": 25}], "metadata": {"scrolled": true, "trusted": true}}, {"source": "np.min(cvModel.avgMetrics)", "cell_type": "code", "execution_count": 30, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "30.81426642031701"}, "execution_count": 30}], "metadata": {"trusted": true}}, {"source": "The best model is a Random Forest regressor, using a subset strategy of 50% of the variables and 20 trees. It achieved an RMSE of 30.81.", "cell_type": "markdown", "metadata": {}}, {"source": "#### Worst performer", "cell_type": "markdown", "metadata": {}}, {"source": "cvModel.getEstimatorParamMaps()[ np.argmax(cvModel.avgMetrics) ]", "cell_type": "code", "execution_count": 26, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "{Param(parent='Pipeline_4d63958e14f5e691468e', name='stages', doc='a list of pipeline stages'): [RFormula_42c8b8393de389d8b760,\n  RandomForestRegressor_483f833d74c3e990ce8d],\n Param(parent='RandomForestRegressor_483f833d74c3e990ce8d', name='featureSubsetStrategy', doc='The number of features to consider for splits at each tree node. Supported options: auto, all, onethird, sqrt, log2, (0.0-1.0], [1-n].'): 'sqrt',\n Param(parent='RandomForestRegressor_483f833d74c3e990ce8d', name='numTrees', doc='Number of trees to train (>= 1).'): 30}"}, "execution_count": 26}], "metadata": {"trusted": true}}, {"source": "np.max(cvModel.avgMetrics)", "cell_type": "code", "execution_count": 31, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "35.210848036877124"}, "execution_count": 31}], "metadata": {"trusted": true}}, {"source": "The worst performer was a Random Forest regressor with a subset strategy of using the square root of the number of variables and 30 trees.\n\nWe can also manually give the index to find out the parameters for a specific model. (Remember, the index corresponds to the avgMetrics array.\n\n#### Best Linear Regression", "cell_type": "markdown", "metadata": {}}, {"source": "# I use 9+ argmin because we know the first 9 results are from the Random Forest iterations\ncvModel.getEstimatorParamMaps()[9 + np.argmin(cvModel.avgMetrics[8:])]", "cell_type": "code", "execution_count": 39, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "{Param(parent='LinearRegression_4183b499386e856ec022', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 1.0,\n Param(parent='LinearRegression_4183b499386e856ec022', name='regParam', doc='regularization parameter (>= 0).'): 0.01,\n Param(parent='Pipeline_4d63958e14f5e691468e', name='stages', doc='a list of pipeline stages'): [RFormula_42c8b8393de389d8b760,\n  LinearRegression_4183b499386e856ec022]}"}, "execution_count": 39}], "metadata": {"trusted": true}}, {"source": "The best Linear Regression model has regularization parameter 0.01 and using L1 (also known as lasso) regularization. The variance in Linear Regression performance (measured as RMSE) was minimal, with all of them being between 33.2 and 33.73.  \n\nFinally, we can test our 'best' model from the training phase on our test sample, which is new, unseen data:", "cell_type": "markdown", "metadata": {}}, {"source": "evaluator.evaluate(cvModel.transform(test_flights))", "cell_type": "code", "execution_count": 28, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "31.228861151885553"}, "execution_count": 28}], "metadata": {"trusted": true}}, {"source": "cvModel.transform(test_flights).limit(10).select(\"label\",\"prediction\").show()", "cell_type": "code", "execution_count": 29, "outputs": [{"output_type": "stream", "name": "stdout", "text": "+-----+------------------+\n|label|        prediction|\n+-----+------------------+\n|-19.0| 28.88757275873146|\n|-19.0| 2.462289130631162|\n|-19.0|1.6668822768061389|\n|-19.0|2.1210669714752477|\n|-18.0|  1.24498749884627|\n|-18.0| 2.462289130631162|\n|-18.0|1.6836043331825006|\n|-18.0|1.6991721935153794|\n|-17.0|  1.24498749884627|\n|-17.0| 2.462289130631162|\n+-----+------------------+\n\n"}], "metadata": {"trusted": true}}], "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "pygments_lexer": "ipython3", "version": "3.4.7", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}}}}