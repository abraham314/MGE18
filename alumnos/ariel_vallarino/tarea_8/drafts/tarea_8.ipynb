{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 8 - Luigi\n",
    "\n",
    "_175904 - Jorge III Altamirano Astorga_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import luigi\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "from luigi.contrib.postgres import CopyToTable, PostgresTarget, PostgresQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: Checking if StartPipeline(producto=) is complete\n",
      "/home/jaa6766/.local/lib/python3.6/site-packages/luigi/worker.py:346: UserWarning: Task StartPipeline(producto=) without outputs has no custom complete() method\n",
      "  is_complete = task.complete()\n",
      "DEBUG: Checking if AggretateByState(producto=) is complete\n",
      "INFO: Informed scheduler that task   StartPipeline__7a52092eb8   has status   PENDING\n",
      "DEBUG: Checking if DropAggTableIfExists(producto=) is complete\n",
      "INFO: Informed scheduler that task   AggretateByState__7a52092eb8   has status   PENDING\n",
      "DEBUG: Checking if InsertDataInDataBase(producto=) is complete\n",
      "INFO: Informed scheduler that task   DropAggTableIfExists__7a52092eb8   has status   PENDING\n",
      "DEBUG: Checking if ConvertJSONToCSV(producto=) is complete\n",
      "INFO: Informed scheduler that task   InsertDataInDataBase__7a52092eb8   has status   PENDING\n",
      "INFO: Informed scheduler that task   ConvertJSONToCSV__7a52092eb8   has status   DONE\n",
      "INFO: Done scheduling tasks\n",
      "INFO: Running Worker with 1 processes\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Pending tasks: 4\n",
      "INFO: [pid 24606] Worker Worker(salt=561148329, workers=1, host=jupyter.corp.penoles.mx, username=jaa6766, pid=24606) running   InsertDataInDataBase(producto=)\n",
      "INFO: Wrote 100000 lines\n",
      "INFO: Wrote 200000 lines\n",
      "INFO: Done writing, importing at 2018-04-25 17:04:37.504373\n",
      "INFO: [pid 24606] Worker Worker(salt=561148329, workers=1, host=jupyter.corp.penoles.mx, username=jaa6766, pid=24606) done      InsertDataInDataBase(producto=)\n",
      "DEBUG: 1 running tasks, waiting for next task to finish\n",
      "INFO: Informed scheduler that task   InsertDataInDataBase__7a52092eb8   has status   DONE\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Pending tasks: 3\n",
      "INFO: [pid 24606] Worker Worker(salt=561148329, workers=1, host=jupyter.corp.penoles.mx, username=jaa6766, pid=24606) running   DropAggTableIfExists(producto=)\n",
      "INFO: Executing query from task: <class '__main__.DropAggTableIfExists'>\n",
      "INFO: [pid 24606] Worker Worker(salt=561148329, workers=1, host=jupyter.corp.penoles.mx, username=jaa6766, pid=24606) done      DropAggTableIfExists(producto=)\n",
      "DEBUG: 1 running tasks, waiting for next task to finish\n",
      "INFO: Informed scheduler that task   DropAggTableIfExists__7a52092eb8   has status   DONE\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Pending tasks: 2\n",
      "INFO: [pid 24606] Worker Worker(salt=561148329, workers=1, host=jupyter.corp.penoles.mx, username=jaa6766, pid=24606) running   AggretateByState(producto=)\n",
      "INFO: Executing query from task: <class '__main__.AggretateByState'>\n",
      "ERROR: [pid 24606] Worker Worker(salt=561148329, workers=1, host=jupyter.corp.penoles.mx, username=jaa6766, pid=24606) failed    AggretateByState(producto=)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jaa6766/.local/lib/python3.6/site-packages/luigi/worker.py\", line 203, in run\n",
      "    new_deps = self._run_get_new_deps()\n",
      "  File \"/home/jaa6766/.local/lib/python3.6/site-packages/luigi/worker.py\", line 140, in _run_get_new_deps\n",
      "    task_gen = self.task.run()\n",
      "  File \"/home/jaa6766/.local/lib/python3.6/site-packages/luigi/contrib/postgres.py\", line 368, in run\n",
      "    cursor.execute(sql)\n",
      "psycopg2.ProgrammingError: function avg(character varying) does not exist\n",
      "LINE 1: SELECT AVG(precio), cadenaComercial INTO agg_ FROM PRODUCTO ...\n",
      "               ^\n",
      "HINT:  No function matches the given name and argument types. You might need to add explicit type casts.\n",
      "\n",
      "DEBUG: 1 running tasks, waiting for next task to finish\n",
      "INFO: Informed scheduler that task   AggretateByState__7a52092eb8   has status   FAILED\n",
      "DEBUG: Asking scheduler for work...\n",
      "DEBUG: Done\n",
      "DEBUG: There are no more tasks to run at this time\n",
      "DEBUG: There are 2 pending tasks possibly being run by other workers\n",
      "DEBUG: There are 2 pending tasks last scheduled by this worker\n",
      "INFO: Worker Worker(salt=561148329, workers=1, host=jupyter.corp.penoles.mx, username=jaa6766, pid=24606) was stopped. Shutting down Keep-Alive thread\n",
      "INFO: \n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 5 tasks of which:\n",
      "* 1 present dependencies were encountered:\n",
      "    - 1 ConvertJSONToCSV(producto=)\n",
      "* 2 ran successfully:\n",
      "    - 1 DropAggTableIfExists(producto=)\n",
      "    - 1 InsertDataInDataBase(producto=)\n",
      "* 1 failed:\n",
      "    - 1 AggretateByState(producto=)\n",
      "* 1 were left pending, among these:\n",
      "    * 1 had failed dependencies:\n",
      "        - 1 StartPipeline(producto=)\n",
      "\n",
      "This progress looks :( because there were failed tasks\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DeleteTableProducto(PostgresQuery):\n",
    "    producto = luigi.Parameter()\n",
    "    host = os.environ.get('DB_HOST', '172.17.0.6:5432')\n",
    "    database = os.environ.get('DB_DATABASE', 'QQP')\n",
    "    user = os.environ.get('DB_USER', 'QQP')\n",
    "    password = os.environ.get('DB_PASSWORD', 'q1q2p')\n",
    "    port = os.environ.get('DB_PORT', 5432)\n",
    "    table = os.environ.get('DB_TABLE','PRODUCTO')\n",
    "    update_id = str(int(round(time.time() * 1000) * random.random()))\n",
    "\n",
    "    @property\n",
    "    def query(self):\n",
    "        return \"DELETE FROM PRODUCTO;\"\n",
    "\n",
    "\n",
    "class DownloadProduct(luigi.Task):\n",
    "    producto = luigi.Parameter()\n",
    "\n",
    "    def requires(self):\n",
    "        return DeleteTableProducto(self.producto)\n",
    "\n",
    "    def run(self):\n",
    "        page = 1\n",
    "        must_continue = True\n",
    "        list_product = []\n",
    "\n",
    "        while must_continue:\n",
    "            print(\"Peticion al API pagina: \", str(page))\n",
    "            self.set_status_message(\"Peticion al API QQP, producto: {} pagina: {}\" \\\n",
    "                                    .format(self.producto, str(page)))\n",
    "            params_response = {'producto': self.producto, 'page': str(page), 'pageSize': str(1000)}\n",
    "            if(len(self.producto) < 1): params_response = {'page': str(page), 'pageSize': str(1000)}\n",
    "            response = requests.get('https://api.datos.gob.mx/v1/profeco.precios', \n",
    "                                    params=params_response)\n",
    "            print(\"Respuesta del servidor\", response.status_code)\n",
    "            if response.status_code == 200:\n",
    "                json_response = response.json().get('results', [])\n",
    "                must_continue = len(json_response) > 0\n",
    "\n",
    "                if must_continue:\n",
    "                    list_product.extend(json_response)\n",
    "                    page += 1\n",
    "\n",
    "        if len(list_product) > 0:\n",
    "            with self.output().open('w') as json_file:\n",
    "                json.dump(list_product, json_file)\n",
    "\n",
    "    def output(self):\n",
    "        return luigi.LocalTarget('/tmp/qqp/{}/data.json'.format(self.producto))\n",
    "\n",
    "\n",
    "class ConvertJSONToCSV(luigi.Task):\n",
    "    producto = luigi.Parameter()\n",
    "\n",
    "    def requires(self):\n",
    "        return DownloadProduct(self.producto)\n",
    "\n",
    "    def run(self):\n",
    "        with self.input().open('r') as json_file:\n",
    "            json_product = json.load(json_file)\n",
    "\n",
    "        print(len(json_product))\n",
    "        headers = json_product[0].keys()\n",
    "\n",
    "        with open('/tmp/qqp/{0}/headers.csv'.format(self.producto), 'w+') as header_file:\n",
    "            json.dump(list(headers), header_file)\n",
    "\n",
    "        with self.output().open('w') as csv_file:\n",
    "            writer = csv.writer(csv_file, delimiter='|', quotechar='\"')\n",
    "\n",
    "            for product in json_product:\n",
    "                writer.writerow(list(product.values()))\n",
    "\n",
    "    def output(self):\n",
    "        return luigi.LocalTarget('/tmp/qqp/{0}/data.csv'.format(self.producto))\n",
    "\n",
    "\n",
    "class InsertDataInDataBase(CopyToTable):\n",
    "    producto = luigi.Parameter()\n",
    "    host = os.environ.get('DB_HOST', '172.17.0.6:5432')\n",
    "    database = os.environ.get('DB_DATABASE', 'QQP')\n",
    "    user = os.environ.get('DB_USER', 'QQP')\n",
    "    password = os.environ.get('DB_PASSWORD', 'q1q2p')\n",
    "    port = os.environ.get('DB_PORT', 5432)\n",
    "    table = os.environ.get('DB_TABLE','PRODUCTO')\n",
    "    update_id = str(int(round(time.time() * 1000) * random.random()))\n",
    "    column_separator = \"|\"\n",
    "\n",
    "    @property\n",
    "    def columns(self):\n",
    "        with open('/tmp/qqp/{0}/headers.csv'.format(self.producto), 'r') as header_file:\n",
    "            return json.load(header_file)\n",
    "\n",
    "    def requires(self):\n",
    "        return ConvertJSONToCSV(self.producto)\n",
    "\n",
    "\n",
    "class DropAggTableIfExists(PostgresQuery):\n",
    "    producto = luigi.Parameter()\n",
    "    host = os.environ.get('DB_HOST', '172.17.0.6:5432')\n",
    "    database = os.environ.get('DB_DATABASE', 'QQP')\n",
    "    user = os.environ.get('DB_USER', 'QQP')\n",
    "    password = os.environ.get('DB_PASSWORD', 'q1q2p')\n",
    "    port = os.environ.get('DB_PORT', 5432)\n",
    "    table = os.environ.get('DB_TABLE','PRODUCTO')\n",
    "    update_id = str(int(round(time.time() * 1000) * random.random()))\n",
    "\n",
    "    @property\n",
    "    def query(self):\n",
    "        return \"DROP TABLE IF EXISTS agg_{0};\".format(self.producto.lower().replace(' ', '_'))\n",
    "\n",
    "    def requires(self):\n",
    "        return InsertDataInDataBase(self.producto)\n",
    "\n",
    "\n",
    "class AggretateByState(PostgresQuery):\n",
    "    producto = luigi.Parameter()\n",
    "    host = os.environ.get('DB_HOST', '172.17.0.6:5432')\n",
    "    database = os.environ.get('DB_DATABASE', 'QQP')\n",
    "    user = os.environ.get('DB_USER', 'QQP')\n",
    "    password = os.environ.get('DB_PASSWORD', 'q1q2p')\n",
    "    port = os.environ.get('DB_PORT', 5432)\n",
    "    table = os.environ.get('DB_TABLE','PRODUCTO')\n",
    "    update_id = str(int(round(time.time() * 1000) * random.random() ))\n",
    "\n",
    "    @property\n",
    "    def query(self):\n",
    "        return \"SELECT AVG(precio), cadenaComercial INTO agg_{0} FROM PRODUCTO GROUP BY cadenaComercial;\" \\\n",
    "            .format(self.producto.lower().replace(' ', '_'))\n",
    "\n",
    "    def requires(self):\n",
    "        return DropAggTableIfExists(self.producto)\n",
    "\n",
    "\n",
    "class StartPipeline(luigi.Task):\n",
    "    producto = luigi.Parameter()\n",
    "\n",
    "    def requires(self):\n",
    "        return AggretateByState(self.producto)\n",
    "    \n",
    "luigi.build([StartPipeline(producto=\"\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster ID=j-2OJ18JX0F6K2S, status=TERMINATED\n",
      "    Instance ID=ci-1LHWIL1RFFNCE, status=TERMINATED\n",
      "    Instance ID=ci-90HEN7609QQ9, status=TERMINATED\n",
      "    Instance ID=ci-2L049BXYMZV6G, status=TERMINATED\n",
      "Cluster ID=j-3GO9154OA62RJ, status=TERMINATED\n",
      "    Instance ID=ci-2REJ34JANE3MY, status=TERMINATED\n",
      "    Instance ID=ci-2TXXYIJK1O5PY, status=TERMINATED\n",
      "    Instance ID=ci-2ESSAVS5YBV6T, status=TERMINATED\n",
      "Cluster ID=j-1V0489WY8SV6, status=TERMINATED\n",
      "    Instance ID=ci-NGBUGUJ9EN44, status=TERMINATED\n",
      "    Instance ID=ci-BVR64HF7HHNE, status=TERMINATED\n",
      "    Instance ID=ci-2MM0THW8YP24H, status=TERMINATED\n",
      "Cluster ID=j-6UU7XES6A0L0, status=TERMINATED\n",
      "    Instance ID=ci-3CF2KSV0V29JJ, status=TERMINATED\n",
      "    Instance ID=ci-2D998SEN7L5GI, status=TERMINATED\n",
      "    Instance ID=ci-3V951XDQBO319, status=TERMINATED\n",
      "Cluster ID=j-1T0U5VYWD2ZWR, status=TERMINATED\n",
      "    Instance ID=ci-1ICYNBTH1ZILR, status=TERMINATED\n",
      "    Instance ID=ci-2EBF7Y7EWWJR6, status=TERMINATED\n",
      "    Instance ID=ci-2I3RRMECH4KRI, status=TERMINATED\n",
      "Cluster ID=j-PWR1B8HU8XZW, status=TERMINATED\n",
      "    Instance ID=ci-2N760B4424A4P, status=TERMINATED\n",
      "    Instance ID=ci-KFRZNBLEB181, status=TERMINATED\n",
      "    Instance ID=ci-2UFO6RG3UBS2K, status=TERMINATED\n",
      "    Instance ID=ci-5QE43IV0JN9S, status=TERMINATED\n",
      "    Instance ID=ci-3C1JLYROM4JXR, status=TERMINATED\n",
      "Cluster ID=j-3OCCKYCXZRK9E, status=TERMINATED\n",
      "    Instance ID=ci-2LGNTE15HG4X4, status=TERMINATED\n",
      "    Instance ID=ci-2C4SHG9QIJ64V, status=TERMINATED\n",
      "    Instance ID=ci-D5OQVKERUU0P, status=TERMINATED\n",
      "Cluster ID=j-QXS2RX9T0LUE, status=TERMINATED\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "emr = boto3.client(\"emr\")\n",
    "clusters = emr.list_clusters()[\"Clusters\"]\n",
    "\n",
    "for cluster in clusters:\n",
    "    status = cluster[\"Status\"]\n",
    "    instances = emr.list_instances(ClusterId = cluster[\"Id\"])[\"Instances\"]\n",
    "    print(\"Cluster ID=%s, status=%s\"%(cluster[\"Id\"], status[\"State\"]))\n",
    "    for instance in instances:\n",
    "        print(\"    Instance ID=%s, status=%s\"%(instance[\"Id\"], instance[\"Status\"][\"State\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting run.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile run.sh\n",
    "git clone git://github.com/yyuu/pyenv.git ~/.pyenv; \n",
    "export PYENV=~/.pyenv; \n",
    "export PATH=\"$PYENV/bin\":\"$PATH\"; \n",
    "eval \"$(pyenv init -)\";\n",
    "# al parecer versiones 3.5.4 encuentran este bug\n",
    "# https://github.com/RobotWebTools/rosbridge_suite/issues/154\n",
    "pyenv install 3.4.7 \n",
    "pyenv shell 3.4.7 && \\ \n",
    "python3 -m pip install -r requirements.txt && \\\n",
    "luigid --background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jaa6766/Documents/jorge3a/itam/metodos_gran_escala/alumnos/jorge_altamirano/tarea_8\n",
      "Requirement already satisfied: luigi==2.7.5 in /home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages (from -r requirements.txt (line 1))\n",
      "Requirement already satisfied: requests==2.18.4 in /home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages (from -r requirements.txt (line 2))\n",
      "Requirement already satisfied: boto3 in /home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages (from -r requirements.txt (line 3))\n",
      "Requirement already satisfied: pyspark in /home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages (from -r requirements.txt (line 4))\n",
      "Requirement already satisfied: pandas in /home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages (from -r requirements.txt (line 5))\n",
      "Requirement already satisfied: numpy in /home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages (from -r requirements.txt (line 6))\n",
      "Requirement already satisfied: tornado<5,>=4.0 in /home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages (from luigi==2.7.5->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: python-daemon<3.0 in /home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages (from luigi==2.7.5->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages (from requests==2.18.4->-r requirements.txt (line 2))\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages (from requests==2.18.4->-r requirements.txt (line 2))\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages (from requests==2.18.4->-r requirements.txt (line 2))\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages (from requests==2.18.4->-r requirements.txt (line 2))\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages (from boto3->-r requirements.txt (line 3))\n",
      "Requirement already satisfied: botocore<1.11.0,>=1.10.10 in /home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages (from boto3->-r requirements.txt (line 3))\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages (from boto3->-r requirements.txt (line 3))\n",
      "Requirement already satisfied: py4j==0.10.6 in /home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages (from pyspark->-r requirements.txt (line 4))\n",
      "Requirement already satisfied: python-dateutil>=2 in /home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages (from pandas->-r requirements.txt (line 5))\n",
      "Requirement already satisfied: pytz>=2011k in /home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages (from pandas->-r requirements.txt (line 5))\n",
      "Requirement already satisfied: backports_abc>=0.4 in /home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages (from tornado<5,>=4.0->luigi==2.7.5->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: docutils in /home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages (from python-daemon<3.0->luigi==2.7.5->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: lockfile>=0.10 in /home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages (from python-daemon<3.0->luigi==2.7.5->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: setuptools in /home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages (from python-daemon<3.0->luigi==2.7.5->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: six>=1.5 in /home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages (from python-dateutil>=2->pandas->-r requirements.txt (line 5))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path '/home/jaa6766/.pyenv' already exists and is not an empty directory.\n",
      "pyenv: /home/jaa6766/.pyenv/versions/3.4.7 already exists\n",
      "./run.sh: line 8:  : command not found\n",
      "You are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jaa6766/.pyenv/versions/3.4.7/bin/luigid\", line 11, in <module>\n",
      "    load_entry_point('luigi==2.7.5', 'console_scripts', 'luigid')()\n",
      "  File \"/home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages/luigi/cmdline.py\", line 15, in luigid\n",
      "    import luigi.server\n",
      "  File \"/home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages/luigi/server.py\", line 48, in <module>\n",
      "    import tornado.httpserver\n",
      "  File \"/home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages/tornado/httpserver.py\", line 34, in <module>\n",
      "    from tornado.http1connection import HTTP1ServerConnection, HTTP1ConnectionParameters\n",
      "  File \"/home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages/tornado/http1connection.py\", line 28, in <module>\n",
      "    from tornado import gen\n",
      "  File \"/home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages/tornado/gen.py\", line 89, in <module>\n",
      "    from tornado.ioloop import IOLoop\n",
      "  File \"/home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages/tornado/ioloop.py\", line 49, in <module>\n",
      "    from tornado.platform.auto import set_close_exec, Waker\n",
      "  File \"/home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages/tornado/platform/auto.py\", line 39, in <module>\n",
      "    from tornado.platform.posix import set_close_exec, Waker\n",
      "  File \"/home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages/tornado/platform/posix.py\", line 21, in <module>\n",
      "    import fcntl\n",
      "ImportError: No module named 'fcntl'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pwd\n",
    "chmod a+rx run.sh\n",
    "./run.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jaa6766/.pyenv/versions/3.4.7/bin/luigid\", line 11, in <module>\n",
      "    load_entry_point('luigi==2.7.5', 'console_scripts', 'luigid')()\n",
      "  File \"/home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages/luigi/cmdline.py\", line 15, in luigid\n",
      "    import luigi.server\n",
      "  File \"/home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages/luigi/server.py\", line 48, in <module>\n",
      "    import tornado.httpserver\n",
      "  File \"/home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages/tornado/httpserver.py\", line 34, in <module>\n",
      "    from tornado.http1connection import HTTP1ServerConnection, HTTP1ConnectionParameters\n",
      "  File \"/home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages/tornado/http1connection.py\", line 28, in <module>\n",
      "    from tornado import gen\n",
      "  File \"/home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages/tornado/gen.py\", line 89, in <module>\n",
      "    from tornado.ioloop import IOLoop\n",
      "  File \"/home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages/tornado/ioloop.py\", line 49, in <module>\n",
      "    from tornado.platform.auto import set_close_exec, Waker\n",
      "  File \"/home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages/tornado/platform/auto.py\", line 39, in <module>\n",
      "    from tornado.platform.posix import set_close_exec, Waker\n",
      "  File \"/home/jaa6766/.pyenv/versions/3.4.7/lib/python3.4/site-packages/tornado/platform/posix.py\", line 21, in <module>\n",
      "    import fcntl\n",
      "ImportError: No module named 'fcntl'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export PYENV=~/.pyenv; \n",
    "export PATH=\"$PYENV/bin\":\"$PATH\"; \n",
    "eval \"$(pyenv init -)\";\n",
    "pyenv shell 3.4.7\n",
    "luigid --background \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importo librerías\n",
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import DataFrameStatFunctions, DataFrame\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import pandas as pd\n",
    "import re as re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#arranque de Spark\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.driver.memory\", \"16g\")\n",
    "conf.set(\"spark.driver.cores\", 4)\n",
    "conf.set(\"spark.driver.memoryOverhead\", 0.9)\n",
    "conf.set(\"spark.executor.memory\", \"32g\")\n",
    "conf.set(\"spark.executor.cores\", 12)\n",
    "conf.set(\"spark.jars\", \"/home/jaa6766\")\n",
    "sc = SparkContext(master = \"local[14]\", sparkHome=\"/usr/local/spark/\", \n",
    "                  appName=\"tarea-mge-8\", conf=conf)\n",
    "spark = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+--------------------+------------+--------+-------------------+--------------------+--------------------+--------------------+--------------------+----------------+-------------------+---------+----------+\n",
      "|            producto|        presentacion|marca|           categoria|    catalogo|  precio|      fechaRegistro|     cadenaComercial|                giro|     nombreComercial|           direccion|          estado|          municipio|  latitud|  longitud|\n",
      "+--------------------+--------------------+-----+--------------------+------------+--------+-------------------+--------------------+--------------------+--------------------+--------------------+----------------+-------------------+---------+----------+\n",
      "|             GAVINDO|CAJA CON 30 TABLETAS|  S/M|        MEDICAMENTOS|MEDICAMENTOS|644.7000|2016-02-11 14:08:13|FARMACIA GUADALAJARA|TIENDA DE AUTOSER...|FARMACIA GUADALAJ...|HIDALGO 42, COL. ...|          MÉXICO|       TLALNEPANTLA|       NA|        NA|\n",
      "|POLVO P/PREPARAR ...|SOBRE 15 GR. NARA...| ZUKO|CHOCOLATES Y GOLO...|     BASICOS|  2.9000|2016-02-11 14:08:14|      BODEGA AURRERA|TIENDA DE AUTOSER...|AURRERA BODEGA SU...|CALZ. DE LA VIGA ...|DISTRITO FEDERAL|VENUSTIANO CARRANZA|19.414749|-99.127874|\n",
      "+--------------------+--------------------+-----+--------------------+------------+--------+-------------------+--------------------+--------------------+--------------------+--------------------+----------------+-------------------+---------+----------+\n",
      "only showing top 2 rows\n",
      "\n",
      "root\n",
      " |-- producto: string (nullable = true)\n",
      " |-- presentacion: string (nullable = true)\n",
      " |-- marca: string (nullable = true)\n",
      " |-- categoria: string (nullable = true)\n",
      " |-- catalogo: string (nullable = true)\n",
      " |-- precio: decimal(16,4) (nullable = true)\n",
      " |-- fechaRegistro: timestamp (nullable = true)\n",
      " |-- cadenaComercial: string (nullable = true)\n",
      " |-- giro: string (nullable = true)\n",
      " |-- nombreComercial: string (nullable = true)\n",
      " |-- direccion: string (nullable = true)\n",
      " |-- estado: string (nullable = true)\n",
      " |-- municipio: string (nullable = true)\n",
      " |-- latitud: string (nullable = true)\n",
      " |-- longitud: string (nullable = true)\n",
      "\n",
      "CPU times: user 32.5 ms, sys: 7.49 ms, total: 40 ms\n",
      "Wall time: 2min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = spark.read.csv(\"hdfs://172.17.0.2:9000/data/profeco/data.csv\", \n",
    "                      schema = StructType() \\\n",
    "                        .add(\"producto\", StringType(), False) \\\n",
    "                        .add(\"presentacion\", StringType(), True) \\\n",
    "                        .add(\"marca\", StringType(), True) \\\n",
    "                        .add(\"categoria\", StringType(), True) \\\n",
    "                        .add(\"catalogo\", StringType(), True) \\\n",
    "                        .add(\"precio\", DecimalType(precision=16, scale=4), True) \\\n",
    "                        .add(\"fechaRegistro\", TimestampType(), True) \\\n",
    "                        .add(\"cadenaComercial\", StringType(), True) \\\n",
    "                        .add(\"giro\", StringType(), True) \\\n",
    "                        .add(\"nombreComercial\", StringType(), True) \\\n",
    "                        .add(\"direccion\", StringType(), True) \\\n",
    "                        .add(\"estado\", StringType(), True) \\\n",
    "                        .add(\"municipio\", StringType(), True) \\\n",
    "                        .add(\"latitud\", StringType(), True) \\\n",
    "                        .add(\"longitud\", StringType(), True),\n",
    "                      inferSchema=False,\n",
    "                      escape='\"',\n",
    "                      quote='\"',\n",
    "                      timestampFormat=\"yyyy-MM-dd hh:mm:ss\",\n",
    "                      header=True)\n",
    "data.write.parquet(\"hdfs://172.17.0.2:9000/data/profeco/data.parquet\", mode=\"overwrite\")\n",
    "data = spark.read.parquet(\"hdfs://172.17.0.2:9000/data/profeco/data.parquet\")\n",
    "data.show(2)\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.1 ms, sys: 8.36 ms, total: 23.5 ms\n",
      "Wall time: 7.32 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1, 44.2, 419.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data.approxQuantile(\"precio\", [0.1, 0.5, 0.85], 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.7 ms, sys: 15.2 ms, total: 46.9 ms\n",
      "Wall time: 4min 5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "62530715"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "data.rdd.countApprox(timeout=1, confidence=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59.6 ms, sys: 22.6 ms, total: 82.2 ms\n",
      "Wall time: 11.4 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>62,530,715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>40.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>268.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>299,999.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg</th>\n",
       "      <td>516.56992236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stddev</th>\n",
       "      <td>1,998.620808903092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    precio\n",
       "count           62,530,715\n",
       "min                 0.1000\n",
       "25%                   20.0\n",
       "50%                   40.9\n",
       "75%                  268.2\n",
       "max           299,999.0000\n",
       "avg           516.56992236\n",
       "stddev  1,998.620808903092"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summary_j3a(col):\n",
    "    cnt1 = pd.DataFrame([{\"count\": data.count()}]).transpose()\n",
    "    min1 = data.select(min(col).alias(\"min\")).toPandas().transpose()\n",
    "    max1 = data.select(max(col).alias(\"max\")).toPandas().transpose()\n",
    "    avg1 = data.select(mean(col).alias(\"avg\")).toPandas().transpose()\n",
    "    std1 = data.select(stddev(col).alias(\"stddev\")).toPandas().transpose()\n",
    "    probs = [0.25, 0.5, 0.75]\n",
    "    qnt1 = pd.DataFrame(  \\\n",
    "        data.approxQuantile(col, probabilities=probs, relativeError=0.05)\n",
    "    )\n",
    "    qnt1 = qnt1.rename_axis({0: \"25%\", 1: \"50%\", 2: \"75%\"}, axis=0)\n",
    "    complete = cnt1.append(min1).append(qnt1).append(max1).append(avg1).append(std1)\n",
    "    complete = complete.rename(index=str, columns={0: col})\n",
    "    complete[col] = complete.apply(lambda x: \"{:,}\".format(x[col]), axis=1)\n",
    "    return complete\n",
    "def summary_string_j3a(col):\n",
    "    cnt1 = pd.DataFrame([{\"count\": data.count()}]).transpose()\n",
    "    min1 = data.select(min(col).alias(\"min\")).toPandas().transpose()\n",
    "    max1 = data.select(max(col).alias(\"max\")).toPandas().transpose()\n",
    "    complete = cnt1.append(min1).append(max1)\n",
    "    complete = complete.rename(index=str, columns={0: col})\n",
    "    return complete\n",
    "%time summary_j3a(\"precio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.8 ms, sys: 10.5 ms, total: 40.3 ms\n",
      "Wall time: 5.63 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>producto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>62530715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>A.S.COR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>ZYPREXA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       producto\n",
       "count  62530715\n",
       "min     A.S.COR\n",
       "max     ZYPREXA"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summary_string_j3a(col):\n",
    "    cnt1 = pd.DataFrame([{\"count\": data.count()}]).transpose()\n",
    "    min1 = data.select(min(col).alias(\"min\")).toPandas().transpose()\n",
    "    max1 = data.select(max(col).alias(\"max\")).toPandas().transpose()\n",
    "    complete = cnt1.append(min1).append(max1)\n",
    "    complete = complete.rename(index=str, columns={0: col})\n",
    "    return complete\n",
    "%time summary_string_j3a(\"producto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+\n",
      "|approx_count_distinct(producto)|\n",
      "+-------------------------------+\n",
      "|                           1100|\n",
      "+-------------------------------+\n",
      "\n",
      "62530715\n",
      "CPU times: user 6 ms, sys: 2.85 ms, total: 8.85 ms\n",
      "Wall time: 6.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data.select(approxCountDistinct(\"producto\", rsd=0.01)).show()\n",
    "print(data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|approx_count_distinct(estado)|\n",
      "+-----------------------------+\n",
      "|                           32|\n",
      "+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(approxCountDistinct(\"estado\", rsd=0.01)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|              estado|\n",
      "+--------------------+\n",
      "|                null|\n",
      "|      AGUASCALIENTES|\n",
      "|     BAJA CALIFORNIA|\n",
      "| BAJA CALIFORNIA SUR|\n",
      "|            CAMPECHE|\n",
      "|             CHIAPAS|\n",
      "|           CHIHUAHUA|\n",
      "|COAHUILA DE ZARAGOZA|\n",
      "|              COLIMA|\n",
      "|    DISTRITO FEDERAL|\n",
      "|             DURANGO|\n",
      "|          GUANAJUATO|\n",
      "|            GUERRERO|\n",
      "|             HIDALGO|\n",
      "|             JALISCO|\n",
      "| MICHOACÁN DE OCAMPO|\n",
      "|             MORELOS|\n",
      "|              MÉXICO|\n",
      "|             NAYARIT|\n",
      "|          NUEVO LEÓN|\n",
      "|              OAXACA|\n",
      "|              PUEBLA|\n",
      "|           QUERÉTARO|\n",
      "|        QUINTANA ROO|\n",
      "|     SAN LUIS POTOSÍ|\n",
      "|             SINALOA|\n",
      "|              SONORA|\n",
      "|             TABASCO|\n",
      "|          TAMAULIPAS|\n",
      "|            TLAXCALA|\n",
      "|VERACRUZ DE IGNAC...|\n",
      "|             YUCATÁN|\n",
      "|           ZACATECAS|\n",
      "+--------------------+\n",
      "\n",
      "CPU times: user 6.31 ms, sys: 4.99 ms, total: 11.3 ms\n",
      "Wall time: 2.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data.select(\"estado\").distinct().orderBy(\"estado\").show(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+-----+---------+--------+------+-------------+---------------+----+---------------+---------+------+---------+-------+--------+\n",
      "|producto|presentacion|marca|categoria|catalogo|precio|fechaRegistro|cadenaComercial|giro|nombreComercial|direccion|estado|municipio|latitud|longitud|\n",
      "+--------+------------+-----+---------+--------+------+-------------+---------------+----+---------------+---------+------+---------+-------+--------+\n",
      "|    null|        null| null|     null|    null|  null|         null|           null|null|           null|     null|  null|     null|   null|    null|\n",
      "|    null|        null| null|     null|    null|  null|         null|           null|null|           null|     null|  null|     null|   null|    null|\n",
      "|    null|        null| null|     null|    null|  null|         null|           null|null|           null|     null|  null|     null|   null|    null|\n",
      "|    null|        null| null|     null|    null|  null|         null|           null|null|           null|     null|  null|     null|   null|    null|\n",
      "|    null|        null| null|     null|    null|  null|         null|           null|null|           null|     null|  null|     null|   null|    null|\n",
      "|    null|        null| null|     null|    null|  null|         null|           null|null|           null|     null|  null|     null|   null|    null|\n",
      "|    null|        null| null|     null|    null|  null|         null|           null|null|           null|     null|  null|     null|   null|    null|\n",
      "|    null|        null| null|     null|    null|  null|         null|           null|null|           null|     null|  null|     null|   null|    null|\n",
      "|    null|        null| null|     null|    null|  null|         null|           null|null|           null|     null|  null|     null|   null|    null|\n",
      "|    null|        null| null|     null|    null|  null|         null|           null|null|           null|     null|  null|     null|   null|    null|\n",
      "|    null|        null| null|     null|    null|  null|         null|           null|null|           null|     null|  null|     null|   null|    null|\n",
      "|    null|        null| null|     null|    null|  null|         null|           null|null|           null|     null|  null|     null|   null|    null|\n",
      "|    null|        null| null|     null|    null|  null|         null|           null|null|           null|     null|  null|     null|   null|    null|\n",
      "|    null|        null| null|     null|    null|  null|         null|           null|null|           null|     null|  null|     null|   null|    null|\n",
      "|    null|        null| null|     null|    null|  null|         null|           null|null|           null|     null|  null|     null|   null|    null|\n",
      "|    null|        null| null|     null|    null|  null|         null|           null|null|           null|     null|  null|     null|   null|    null|\n",
      "|    null|        null| null|     null|    null|  null|         null|           null|null|           null|     null|  null|     null|   null|    null|\n",
      "|    null|        null| null|     null|    null|  null|         null|           null|null|           null|     null|  null|     null|   null|    null|\n",
      "|    null|        null| null|     null|    null|  null|         null|           null|null|           null|     null|  null|     null|   null|    null|\n",
      "|    null|        null| null|     null|    null|  null|         null|           null|null|           null|     null|  null|     null|   null|    null|\n",
      "+--------+------------+-----+---------+--------+------+-------------+---------------+----+---------------+---------+------+---------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.filter(\"estado is null\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------+-----+---------+--------+------+--------------------+--------------------+--------------------+---------------+--------------------+----------------+--------------------+---------+----------+\n",
      "|          producto|presentacion|marca|categoria|catalogo|precio|       fechaRegistro|     cadenaComercial|                giro|nombreComercial|           direccion|          estado|           municipio|  latitud|  longitud|\n",
      "+------------------+------------+-----+---------+--------+------+--------------------+--------------------+--------------------+---------------+--------------------+----------------+--------------------+---------+----------+\n",
      "|PAN BLANCO BOLILLO|       PIEZA|  S/M|      PAN| BASICOS|   1.5|2014-12-09 00:00:...|PANADERIAS TRADIC...|PANADERIA Y PASTE...|  PAN BARCELONA|ORIENTE 100 \"\"A\"\"...|DISTRITO FEDERAL|IZTACALCO        ...|19.395734|-99.101886|\n",
      "|PAN BLANCO BOLILLO|       PIEZA|  S/M|      PAN| BASICOS|   1.5|2012-10-23 00:00:...|PANADERIAS TRADIC...|PANADERIA Y PASTE...|  PAN BARCELONA|ORIENTE 100 \"\"A\"\"...|DISTRITO FEDERAL|IZTACALCO        ...|19.395734|-99.101886|\n",
      "|PAN BLANCO BOLILLO|       PIEZA|  S/M|      PAN| BASICOS|   1.5|2012-04-24 00:00:...|PANADERIAS TRADIC...|PANADERIA Y PASTE...|  PAN BARCELONA|ORIENTE 100 \"\"A\"\"...|DISTRITO FEDERAL|IZTACALCO        ...|19.395734|-99.101886|\n",
      "|PAN BLANCO BOLILLO|       PIEZA|  S/M|      PAN| BASICOS|   1.5|2012-07-24 00:00:...|PANADERIAS TRADIC...|PANADERIA Y PASTE...|  PAN BARCELONA|ORIENTE 100 \"\"A\"\"...|DISTRITO FEDERAL|IZTACALCO        ...|19.395734|-99.101886|\n",
      "|PAN BLANCO BOLILLO|       PIEZA|  S/M|      PAN| BASICOS|   1.5|2012-05-22 00:00:...|PANADERIAS TRADIC...|PANADERIA Y PASTE...|  PAN BARCELONA|ORIENTE 100 \"\"A\"\"...|DISTRITO FEDERAL|IZTACALCO        ...|19.395734|-99.101886|\n",
      "|PAN BLANCO BOLILLO|       PIEZA|  S/M|      PAN| BASICOS|   1.5|2012-06-19 00:00:...|PANADERIAS TRADIC...|PANADERIA Y PASTE...|  PAN BARCELONA|ORIENTE 100 \"\"A\"\"...|DISTRITO FEDERAL|IZTACALCO        ...|19.395734|-99.101886|\n",
      "|PAN BLANCO BOLILLO|       PIEZA|  S/M|      PAN| BASICOS|   1.5|2012-03-20 00:00:...|PANADERIAS TRADIC...|PANADERIA Y PASTE...|  PAN BARCELONA|ORIENTE 100 \"\"A\"\"...|DISTRITO FEDERAL|IZTACALCO        ...|19.395734|-99.101886|\n",
      "|PAN BLANCO BOLILLO|       PIEZA|  S/M|      PAN| BASICOS|   1.5|2012-09-25 00:00:...|PANADERIAS TRADIC...|PANADERIA Y PASTE...|  PAN BARCELONA|ORIENTE 100 \"\"A\"\"...|DISTRITO FEDERAL|IZTACALCO        ...|19.395734|-99.101886|\n",
      "|PAN BLANCO BOLILLO|       PIEZA|  S/M|      PAN| BASICOS|   1.5|2012-08-28 00:00:...|PANADERIAS TRADIC...|PANADERIA Y PASTE...|  PAN BARCELONA|ORIENTE 100 \"\"A\"\"...|DISTRITO FEDERAL|IZTACALCO        ...|19.395734|-99.101886|\n",
      "|PAN BLANCO BOLILLO|       PIEZA|  S/M|      PAN| BASICOS|   1.5|2012-05-29 00:00:...|PANADERIAS TRADIC...|PANADERIA Y PASTE...|  PAN BARCELONA|ORIENTE 100 \"\"A\"\"...|DISTRITO FEDERAL|IZTACALCO        ...|19.395734|-99.101886|\n",
      "|PAN BLANCO BOLILLO|       PIEZA|  S/M|      PAN| BASICOS|   1.5|2012-03-27 00:00:...|PANADERIAS TRADIC...|PANADERIA Y PASTE...|  PAN BARCELONA|ORIENTE 100 \"\"A\"\"...|DISTRITO FEDERAL|IZTACALCO        ...|19.395734|-99.101886|\n",
      "|PAN BLANCO BOLILLO|       PIEZA|  S/M|      PAN| BASICOS|   1.5|2012-11-27 00:00:...|PANADERIAS TRADIC...|PANADERIA Y PASTE...|  PAN BARCELONA|ORIENTE 100 \"\"A\"\"...|DISTRITO FEDERAL|IZTACALCO        ...|19.395734|-99.101886|\n",
      "|PAN BLANCO BOLILLO|       PIEZA|  S/M|      PAN| BASICOS|   1.5|2012-02-28 00:00:...|PANADERIAS TRADIC...|PANADERIA Y PASTE...|  PAN BARCELONA|ORIENTE 100 \"\"A\"\"...|DISTRITO FEDERAL|IZTACALCO        ...|19.395734|-99.101886|\n",
      "|PAN BLANCO BOLILLO|       PIEZA|  S/M|      PAN| BASICOS|   1.5|2012-06-26 00:00:...|PANADERIAS TRADIC...|PANADERIA Y PASTE...|  PAN BARCELONA|ORIENTE 100 \"\"A\"\"...|DISTRITO FEDERAL|IZTACALCO        ...|19.395734|-99.101886|\n",
      "|PAN BLANCO BOLILLO|       PIEZA|  S/M|      PAN| BASICOS|   1.5|2012-10-02 00:00:...|PANADERIAS TRADIC...|PANADERIA Y PASTE...|  PAN BARCELONA|ORIENTE 100 \"\"A\"\"...|DISTRITO FEDERAL|IZTACALCO        ...|19.395734|-99.101886|\n",
      "|PAN BLANCO BOLILLO|       PIEZA|  S/M|      PAN| BASICOS|   1.5|2012-08-21 00:00:...|PANADERIAS TRADIC...|PANADERIA Y PASTE...|  PAN BARCELONA|ORIENTE 100 \"\"A\"\"...|DISTRITO FEDERAL|IZTACALCO        ...|19.395734|-99.101886|\n",
      "|PAN BLANCO BOLILLO|       PIEZA|  S/M|      PAN| BASICOS|   1.5|2012-04-10 00:00:...|PANADERIAS TRADIC...|PANADERIA Y PASTE...|  PAN BARCELONA|ORIENTE 100 \"\"A\"\"...|DISTRITO FEDERAL|IZTACALCO        ...|19.395734|-99.101886|\n",
      "|PAN BLANCO BOLILLO|       PIEZA|  S/M|      PAN| BASICOS|   1.5|2012-07-10 00:00:...|PANADERIAS TRADIC...|PANADERIA Y PASTE...|  PAN BARCELONA|ORIENTE 100 \"\"A\"\"...|DISTRITO FEDERAL|IZTACALCO        ...|19.395734|-99.101886|\n",
      "|PAN BLANCO BOLILLO|       PIEZA|  S/M|      PAN| BASICOS|   1.5|2012-09-18 00:00:...|PANADERIAS TRADIC...|PANADERIA Y PASTE...|  PAN BARCELONA|ORIENTE 100 \"\"A\"\"...|DISTRITO FEDERAL|IZTACALCO        ...|19.395734|-99.101886|\n",
      "|PAN BLANCO BOLILLO|       PIEZA|  S/M|      PAN| BASICOS|   1.5|2012-12-18 00:00:...|PANADERIAS TRADIC...|PANADERIA Y PASTE...|  PAN BARCELONA|ORIENTE 100 \"\"A\"\"...|DISTRITO FEDERAL|IZTACALCO        ...|19.395734|-99.101886|\n",
      "+------------------+------------+-----+---------+--------+------+--------------------+--------------------+--------------------+---------------+--------------------+----------------+--------------------+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.filter(\"direccion like '%ESQ. SUR 125%' \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|fechaRegistro      |\n",
      "+-------------------+\n",
      "|2016-02-11 14:08:13|\n",
      "|2016-02-11 14:08:14|\n",
      "|2016-02-11 14:08:14|\n",
      "|2016-02-11 14:08:14|\n",
      "|2016-02-11 14:08:15|\n",
      "|2016-02-11 14:08:16|\n",
      "|2016-02-11 14:08:17|\n",
      "|2016-02-11 14:08:19|\n",
      "|2016-02-11 14:08:19|\n",
      "|2016-02-11 14:08:19|\n",
      "|2016-02-11 14:08:20|\n",
      "|2016-02-11 14:08:20|\n",
      "|2016-02-11 14:08:22|\n",
      "|2016-02-11 14:08:22|\n",
      "|2016-02-11 14:08:24|\n",
      "|2016-02-11 14:08:25|\n",
      "|2016-02-11 14:08:27|\n",
      "|2016-02-11 14:08:27|\n",
      "|2016-02-11 14:08:27|\n",
      "|2016-02-11 14:08:28|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(col(\"fechaRegistro\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliografía\n",
    "\n",
    "* <https://github.com/spotify/luigi/>\n",
    "* <https://github.com/spotify/luigi/issues/1116>\n",
    "* <https://github.com/spotify/luigi/blob/master/examples/pyspark_wc.py>\n",
    "* <http://bionics.it/posts/luigi-tutorial>\n",
    "* <https://stackoverflow.com/questions/2697039/python-equivalent-of-setinterval>\n",
    "* <https://stackoverflow.com/questions/40218393/how-to-configure-luigi-task-retry-correctly>\n",
    "* <https://stackoverflow.com/questions/23302184/running-pyspark-script-on-emr>\n",
    "* <https://stackoverflow.com/questions/9942594/unicodeencodeerror-ascii-codec-cant-encode-character-u-xa0-in-position-20>\n",
    "* <https://stackoverflow.com/a/39293287>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
