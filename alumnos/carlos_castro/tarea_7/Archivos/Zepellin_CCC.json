{"paragraphs":[{"text":"%pyspark \n#Cargamos las funcionalidades de spark en el notebook\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.sql import SparkSession\nfrom pyspark.ml.regression import GeneralizedLinearRegression\n\n\n    \nflights =spark.read.csv(\"s3a://jorge-altamirano/flights/flights.csv\", header = True, inferSchema = True)\n\n#Como vimos en clase, algunas variables necesitan ser modificadas para ser utilizadas en los modelos de ML\n#la mayor parte de este código fue tomada directamente de las notas de clase y documentación\n#Hacemos los arreglos necesarios a las varibles, hot encoder y tokenizer\nfrom pyspark.ml.feature import OneHotEncoder, StringIndexer\nfrom pyspark.ml import Pipeline\n\nvariables = [\"AIRLINE\",\"ORIGIN_AIRPORT\",\"DESTINATION_AIRPORT\",\"DAY_OF_WEEK\"]\nvariables_string_encoded=[\"AIRLINE_strenc\",\"ORIGIN_AIRPORT_strenc\",\"DESTINATION_AIRPORT_strenc\",\"DAY_OF_WEEK_strenc\"]\n\nstage_string = [StringIndexer(inputCol= c, outputCol= c+\"_strenc\") for c in variables]\nstage_one_hot = [OneHotEncoder(inputCol= c+\"_strenc\", outputCol= c+ \"_one_hot\") for c in variables]\n\nppl = Pipeline(stages= stage_string + stage_one_hot)\nflights = ppl.fit(flights).transform(flights)\n\nfrom pyspark.ml.feature import HashingTF, Tokenizer\n\ntokenizer = Tokenizer(inputCol=\"CANCELLATION_REASON\", outputCol=\"CANCELLATION_REASON_tok\")\nhashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"CANCELLATION_REASON_hash\")\n\n\nflights = flights.dropna(how='any', thresh=None, subset=[\"YEAR\",\"MONTH\",\"DAY\",\"FLIGHT_NUMBER\",\"SCHEDULED_DEPARTURE\",\"DEPARTURE_TIME\",\"TAXI_OUT\", \"WHEELS_OFF\", \"SCHEDULED_TIME\",\"ELAPSED_TIME\",\"AIR_TIME\",\"DISTANCE\",\"WHEELS_OFF\",\"SCHEDULED_TIME\", \"ARRIVAL_TIME\",\"ARRIVAL_DELAY\"])\n\n#Antes de pasar mis datos a un cluster de AWS voy a probar mi código localmente utilizando una imagen de Spark en Jupyter\n#https://medium.com/@suci/running-pyspark-on-jupyter-notebook-with-docker-602b18ac4494\nflights = flights.sample(False, .0001, 103531)\nflights.count()\n\n#Preparo mis datos\n#A diferencia del ejecicio visto en clase, es necesario definir un conjunto de variables explicativas \n#para poder utilizar los modelo de ML. Tomaremos las variables que ya transformamos junto con algunas  \n#de las originales para formar el vector \"features\" que fungirá como variables explicativas de la regresión.\n#En clase únicamente fue necesario genera un dataset con el nombre de las columnas que se necesita, \n#aquí tenemos que \"empaquetar\" algunas variables para utilizarlas como X en nuestros modelos de ML.\n\n#Para los 2 modelos de ML que voy a utilizar(regresión lineal y random forest) utilizaré el mismo vector \"features\"\n#Para definir el vetor de features para mi regresión lineal\nfrom pyspark.ml.feature import VectorAssembler\n\nvariables_int=[\"YEAR\",\"MONTH\",\"DAY\",\"FLIGHT_NUMBER\",\"SCHEDULED_DEPARTURE\",\"DEPARTURE_TIME\",\"TAXI_OUT\",\n              \"WHEELS_OFF\", \"SCHEDULED_TIME\",\"ELAPSED_TIME\",\"AIR_TIME\",\"DISTANCE\",\"WHEELS_OFF\",\"SCHEDULED_TIME\",\n              \"ARRIVAL_TIME\",\"ARRIVAL_DELAY\"]\n\nvariables_trans=[\"AIRLINE_one_hot\",\"ORIGIN_AIRPORT_one_hot\",\"DESTINATION_AIRPORT_one_hot\",\"DAY_OF_WEEK_one_hot\"]\n\n#Este es el paquete de variables explicativas que voy a considerar en mi ejercicio:\nfeatures = variables_int + variables_trans\n\nvector_assembler = VectorAssembler(inputCols = features, outputCol= \"features\")\n\nflights = vector_assembler.transform(flights)\n\n#Separamos en entrenamiento y prueba\ntrain = flights.sample(False, 0.7, 103531)\ntest = flights.subtract(train)\ntrain.count()#Tamaño de nuestro conjunto de entrenamiento\n\ntest.count()\n\n#El primer modelo para la predicción del DEPARTURE_DELAY será el modelo de regresión lineal\n#Nota: primero voy a probar el correcto funcionamiento de mis modelos de forma individual. \n# --- Regresión Lineal ---\nfrom pyspark.ml.regression import LinearRegression\n\n#lr =  LinearRegression(labelCol = \"DEPARTURE_DELAY\", featuresCol = \"features\", maxIter = 20)\n#lr_model = lr.fit(train)\n\n\n\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.evaluation import RegressionEvaluator \n\nvery_small_sample = flights.sample(False, 0.1).cache()\n\n#pca_model = PCA(inputCol = \"features\", outputCol = \"features_cv\")\nlr = LinearRegression(labelCol = \"DEPARTURE_DELAY\", featuresCol = \"features\")\nppl_cv = Pipeline(stages = [lr])\n\nparamGrid = ParamGridBuilder() \\\n    .addGrid(lr.maxIter, [5, 10]) \\\n    .build()\n\nvery_small_sample.count()\n\ncrossval = CrossValidator(estimator = ppl_cv,\n                        estimatorParamMaps=paramGrid,\n                        evaluator = RegressionEvaluator(\n    labelCol=\"DEPARTURE_DELAY\", predictionCol=\"prediction\", metricName=\"rmse\"),\n                        numFolds= 3)\n\ncv_model = crossval.fit(very_small_sample)\n\npredictions = cv_model.transform(test)\nevaluator = RegressionEvaluator(labelCol = \"DEPARTURE_DELAY\", predictionCol=\"prediction\", metricName= \"rmse\")\nrmse = evaluator.evaluate(predictions)\n\npredictions.select(\"DEPARTURE_DELAY\",\"prediction\").show(5)\n\n\nprint(rmse)\n\ncv_model.bestModel.stages[0].extractParamMap()\n\nfrom pyspark.ml.regression import RandomForestRegressor\n\n(training_data, test_data) = flights.randomSplit([0.7, 0.3])\nrf = RandomForestRegressor(labelCol = \"DEPARTURE_DELAY\", featuresCol = \"features\", numTrees = 20)\nrf_model = rf.fit(training_data)\n\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.evaluation import RegressionEvaluator \n\nvery_small_sample = flights.sample(False, 0.1).cache()\n\n#pca_model = PCA(inputCol = \"features\", outputCol = \"features_cv\")\nrf = RandomForestRegressor(labelCol = \"DEPARTURE_DELAY\", featuresCol = \"features\")\nppl_cv = Pipeline(stages = [rf])\n\nparamGrid = ParamGridBuilder() \\\n    .addGrid(rf.numTrees, [20, 30]) \\\n    .addGrid(rf.maxDepth,[5,10]) \\\n    .build()\n    \ncrossval = CrossValidator(estimator = ppl_cv,\n                        estimatorParamMaps=paramGrid,\n                        evaluator = RegressionEvaluator(\n    labelCol=\"DEPARTURE_DELAY\", predictionCol=\"prediction\", metricName=\"rmse\"),\n                        numFolds= 3)\n\ncv_model = crossval.fit(very_small_sample)\n\n\n\npredictions = cv_model.transform(test_data)\nevaluator = RegressionEvaluator(labelCol = \"DEPARTURE_DELAY\", predictionCol=\"prediction\", metricName= \"rmse\")\nrmse = evaluator.evaluate(predictions)\n\npredictions.select(\"DEPARTURE_DELAY\",\"prediction\").show(5)\n\nprint(rmse)\n\nclassifiers = {\n         'GLR': GeneralizedLinearRegression(labelCol = \"DEPARTURE_DELAY\", featuresCol = \"features\"),\n         'LR': LinearRegression(labelCol = \"DEPARTURE_DELAY\", featuresCol = \"features\")}\n\ngrid = {\n    \"GLR\":ParamGridBuilder() \\\n    .addGrid(GeneralizedLinearRegression.regParam, [.1, .5,.75]) \\\n    .addGrid(GeneralizedLinearRegression.maxIter,[100,200,500]) \\\n    .build(),\n    \n    \"LR\":ParamGridBuilder() \\\n    .addGrid(lr.regParam, [.05, .25,.45]) \\\n    .addGrid(lr.maxIter,[100,200,50]) \\\n    .build()\n     }\n\nlista=[\"GLR\",\"LR\"]\n\n\nclassifiers[lista[0]]\nfor i in range(1,3):\n    modelo = classifiers[lista[i-1]]\n    modelo_cv = modelo\n    paramGrid=grid[lista[i-1]]\n    \n    crossval = CrossValidator(estimator = modelo_cv,\n                        estimatorParamMaps=paramGrid,\n                        evaluator = RegressionEvaluator(\n    labelCol=\"DEPARTURE_DELAY\", predictionCol=\"prediction\", metricName=\"rmse\"),\n                        numFolds= 10)\n\n    cv_model = crossval.fit(very_small_sample)\n    \n    \n    predictions = cv_model.transform(test_data)\n    evaluator= RegressionEvaluator(labelCol = \"DEPARTURE_DELAY\", predictionCol=\"prediction\", metricName= \"rmse\")\n    rmse = evaluator.evaluate(predictions)\n    print(lista[i-1])\n    print(predictions.select(\"DEPARTURE_DELAY\",\"prediction\").show(5))\n    print(rmse)\n    print(cv_model.bestModel.extractParamMap())\n    i=i+1\n    \n\n\ncrossval = CrossValidator(estimator = modelo_cv,\n                        estimatorParamMaps=paramGrid,\n                        evaluator = RegressionEvaluator(\n    labelCol=\"DEPARTURE_DELAY\", predictionCol=\"prediction\", metricName=\"rmse\"),\n                        numFolds= 3)\n\ncv_model = crossval.fit(very_small_sample)\n\n\n\npredictions = cv_model.transform(test_data)\nevaluator= RegressionEvaluator(labelCol = \"DEPARTURE_DELAY\", predictionCol=\"prediction\", metricName= \"rmse\")\nrmse = evaluator.evaluate(predictions)\nprint(predictions.select(\"DEPARTURE_DELAY\",\"prediction\").show(5))\nprint(rmse)\n#print(cv_model.bestModel.stages[0].extractParamMap())\n\nprint(cv_model.bestModel.extractParamMap())\n\n\n","user":"anonymous","dateUpdated":"2018-04-23T03:59:06+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+---------------+------------------+\n|DEPARTURE_DELAY|        prediction|\n+---------------+------------------+\n|             -4|3.8119424084759785|\n|             -1|19.714050940681936|\n|             13|45.012261967904905|\n|             -1| 4.643484756254269|\n|             76| 75.87725043753653|\n+---------------+------------------+\nonly showing top 5 rows\n\n30.772779802\n+---------------+--------------------+\n|DEPARTURE_DELAY|          prediction|\n+---------------+--------------------+\n|              1|-0.36277264871653897|\n|             53|  24.631017612120385|\n|             -2|   3.568865530727462|\n|              1|    2.70983575052377|\n|             -7|   5.596960083526317|\n+---------------+--------------------+\nonly showing top 5 rows\n\n32.0513718611\nGLR\n+---------------+-------------------+\n|DEPARTURE_DELAY|         prediction|\n+---------------+-------------------+\n|              1|-11.459454659511055|\n|             53|  17.73050314137478|\n|             -2|  7.101505643658189|\n|              1|-12.516873087361207|\n|             -7|  18.01014633432817|\n+---------------+-------------------+\nonly showing top 5 rows\n\nNone\n29.8305422932\n{Param(parent=u'GeneralizedLinearRegression_4116b97e811732342758', name='variancePower', doc='The power in the variance function of the Tweedie distribution which characterizes the relationship between the variance and mean of the distribution. Only applicable to the Tweedie family. Supported values: 0 and [1, Inf).'): 0.0, Param(parent=u'GeneralizedLinearRegression_4116b97e811732342758', name='family', doc='The name of family which is a description of the error distribution to be used in the model. Supported options: gamma, poisson, gaussian, binomial, tweedie.'): 'gaussian', Param(parent=u'GeneralizedLinearRegression_4116b97e811732342758', name='fitIntercept', doc='whether to fit an intercept term'): True, Param(parent=u'GeneralizedLinearRegression_4116b97e811732342758', name='maxIter', doc='maximum number of iterations (>= 0)'): 25, Param(parent=u'GeneralizedLinearRegression_4116b97e811732342758', name='solver', doc='The solver algorithm for optimization. Supported options: irls. (Default irls)'): 'irls', Param(parent=u'GeneralizedLinearRegression_4116b97e811732342758', name='featuresCol', doc='features column name'): 'features', Param(parent=u'GeneralizedLinearRegression_4116b97e811732342758', name='regParam', doc='regularization parameter (>= 0)'): 0.0, Param(parent=u'GeneralizedLinearRegression_4116b97e811732342758', name='predictionCol', doc='prediction column name'): 'prediction', Param(parent=u'GeneralizedLinearRegression_4116b97e811732342758', name='labelCol', doc='label column name'): 'DEPARTURE_DELAY', Param(parent=u'GeneralizedLinearRegression_4116b97e811732342758', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0)'): 1e-06}\nLR\n+---------------+-------------------+\n|DEPARTURE_DELAY|         prediction|\n+---------------+-------------------+\n|              1|-11.459454659511055|\n|             53|  17.73050314137478|\n|             -2|  7.101505643658189|\n|              1|-12.516873087361207|\n|             -7|  18.01014633432817|\n+---------------+-------------------+\nonly showing top 5 rows\n\nNone\n29.8305422932\n{Param(parent=u'LinearRegression_45a0adc7cb1e3a5160b8', name='featuresCol', doc='features column name'): 'features', Param(parent=u'LinearRegression_45a0adc7cb1e3a5160b8', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty'): 0.0, Param(parent=u'LinearRegression_45a0adc7cb1e3a5160b8', name='regParam', doc='regularization parameter (>= 0)'): 0.0, Param(parent=u'LinearRegression_45a0adc7cb1e3a5160b8', name='epsilon', doc='The shape parameter to control the amount of robustness. Must be > 1.0.'): 1.35, Param(parent=u'LinearRegression_45a0adc7cb1e3a5160b8', name='labelCol', doc='label column name'): 'DEPARTURE_DELAY', Param(parent=u'LinearRegression_45a0adc7cb1e3a5160b8', name='standardization', doc='whether to standardize the training features before fitting the model'): True, Param(parent=u'LinearRegression_45a0adc7cb1e3a5160b8', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0)'): 1e-06, Param(parent=u'LinearRegression_45a0adc7cb1e3a5160b8', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2)'): 2, Param(parent=u'LinearRegression_45a0adc7cb1e3a5160b8', name='solver', doc='The solver algorithm for optimization. Supported options: auto, normal, l-bfgs. (Default auto)'): 'auto', Param(parent=u'LinearRegression_45a0adc7cb1e3a5160b8', name='fitIntercept', doc='whether to fit an intercept term'): True, Param(parent=u'LinearRegression_45a0adc7cb1e3a5160b8', name='predictionCol', doc='prediction column name'): 'prediction', Param(parent=u'LinearRegression_45a0adc7cb1e3a5160b8', name='maxIter', doc='maximum number of iterations (>= 0)'): 100, Param(parent=u'LinearRegression_45a0adc7cb1e3a5160b8', name='loss', doc='The loss function to be optimized. Supported options: squaredError, huber. (Default squaredError)'): 'squaredError'}\n+---------------+-------------------+\n|DEPARTURE_DELAY|         prediction|\n+---------------+-------------------+\n|              1|-11.459454659511055|\n|             53|  17.73050314137478|\n|             -2|  7.101505643658189|\n|              1|-12.516873087361207|\n|             -7|  18.01014633432817|\n+---------------+-------------------+\nonly showing top 5 rows\n\nNone\n29.8305422932\n{Param(parent=u'LinearRegression_45a0adc7cb1e3a5160b8', name='featuresCol', doc='features column name'): 'features', Param(parent=u'LinearRegression_45a0adc7cb1e3a5160b8', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty'): 0.0, Param(parent=u'LinearRegression_45a0adc7cb1e3a5160b8', name='regParam', doc='regularization parameter (>= 0)'): 0.0, Param(parent=u'LinearRegression_45a0adc7cb1e3a5160b8', name='epsilon', doc='The shape parameter to control the amount of robustness. Must be > 1.0.'): 1.35, Param(parent=u'LinearRegression_45a0adc7cb1e3a5160b8', name='labelCol', doc='label column name'): 'DEPARTURE_DELAY', Param(parent=u'LinearRegression_45a0adc7cb1e3a5160b8', name='standardization', doc='whether to standardize the training features before fitting the model'): True, Param(parent=u'LinearRegression_45a0adc7cb1e3a5160b8', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0)'): 1e-06, Param(parent=u'LinearRegression_45a0adc7cb1e3a5160b8', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2)'): 2, Param(parent=u'LinearRegression_45a0adc7cb1e3a5160b8', name='solver', doc='The solver algorithm for optimization. Supported options: auto, normal, l-bfgs. (Default auto)'): 'auto', Param(parent=u'LinearRegression_45a0adc7cb1e3a5160b8', name='fitIntercept', doc='whether to fit an intercept term'): True, Param(parent=u'LinearRegression_45a0adc7cb1e3a5160b8', name='predictionCol', doc='prediction column name'): 'prediction', Param(parent=u'LinearRegression_45a0adc7cb1e3a5160b8', name='maxIter', doc='maximum number of iterations (>= 0)'): 100, Param(parent=u'LinearRegression_45a0adc7cb1e3a5160b8', name='loss', doc='The loss function to be optimized. Supported options: squaredError, huber. (Default squaredError)'): 'squaredError'}\n"}]},"apps":[],"jobName":"paragraph_1524452678003_1650768284","id":"20180423-030438_739689418","dateCreated":"2018-04-23T03:04:38+0000","dateStarted":"2018-04-23T03:59:06+0000","dateFinished":"2018-04-23T05:00:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:286"},{"text":"%pyspark\n","user":"anonymous","dateUpdated":"2018-04-23T03:07:38+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1524452858902_1682362022","id":"20180423-030738_2136023188","dateCreated":"2018-04-23T03:07:38+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:287"}],"name":"Tarea 7","id":"2DDEBG96D","angularObjects":{"2BRWU4WXC:shared_process":[],"2AM1YV5CU:shared_process":[],"2AJXGMUUJ:shared_process":[],"2ANGGHHMQ:shared_process":[],"2AKK3QQXU:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}