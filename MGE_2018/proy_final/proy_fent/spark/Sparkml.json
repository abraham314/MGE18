{"paragraphs":[{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python","tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1526924372803_-220981608","id":"20180521-173932_48921784","dateCreated":"2018-05-21T17:39:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:179","text":"%pyspark\nfrom pyspark.sql import SQLContext\nfrom pyspark.sql.types import *\nimport pyspark.sql.functions as functions\nfrom pyspark.sql.functions import desc\nfrom pyspark.sql.functions import col\nimport numpy as np\nfrom pyspark.sql.functions import lit","dateUpdated":"2018-05-21T17:49:50+0000","dateFinished":"2018-05-21T17:49:50+0000","dateStarted":"2018-05-21T17:49:50+0000","results":{"code":"SUCCESS","msg":[]}},{"text":"%pyspark\nsqlContext = SQLContext(sc)\n\n# DATOS DE DEFUNCIONES EN MEXICO\ndefun_2016 = sqlContext.read.load('s3://examen2granescala/defun_2016.csv', \n                      format='com.databricks.spark.csv', \n                      header='true', \n                      inferSchema='true')\n\n# DICCIONARIO DE DATOS\ndiccionario = sqlContext.read.load('s3://examen2granescala/diccionario_datos_defun2016.csv', \n                      format='com.databricks.spark.csv', \n                      header='true', \n                      inferSchema='true')\n\n# ENTIDADES DEL PAIS\ndecateml = sqlContext.read.load('s3://examen2granescala/decateml.csv', \n                      format='com.databricks.spark.csv', \n                      header='true', \n                      inferSchema='true')\n\n# CAUSA DEL DECESO\ndecatcausa = sqlContext.read.load('s3://examen2granescala/decatcausa.csv', \n                      format='com.databricks.spark.csv', \n                      header='true', \n                      inferSchema='true')\n\n# EDAD\ndeedad = sqlContext.read.load('s3://examen2granescala/deedad.csv', \n                      format='com.databricks.spark.csv', \n                      header='true', \n                      inferSchema='true')\n\n# SEXO\ndesexo = sqlContext.read.load('s3://examen2granescala/desexo.csv', \n                      format='com.databricks.spark.csv', \n                      header='true', \n                      inferSchema='true')","user":"anonymous","dateUpdated":"2018-05-21T17:49:54+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1526924436788_-1744294448","id":"20180521-174036_1234147420","dateCreated":"2018-05-21T17:40:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:350","dateFinished":"2018-05-21T17:50:32+0000","dateStarted":"2018-05-21T17:49:54+0000","results":{"code":"SUCCESS","msg":[]}},{"text":"%pyspark\nresp4a = defun_2016.select(\"causa_def\",\"ent_ocurr\").filter((defun_2016.causa_def == 'B150') | (defun_2016.causa_def == 'B159')).groupby('ent_ocurr').agg(functions.count('causa_def').alias('cuenta')).sort(desc(\"cuenta\")).join(decateml.filter((decateml.cve_mun == 0) & (decateml.cve_loc == 0)),defun_2016.ent_ocurr == decateml.cve_ent).select(\"cuenta\",\"nom_loc\")\nresp4a.write.parquet(\"s3://examen2granescala/output4a/proto.parquet\")","user":"anonymous","dateUpdated":"2018-05-21T17:51:20+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1526924857623_-1060032471","id":"20180521-174737_1422601036","dateCreated":"2018-05-21T17:47:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:488","dateFinished":"2018-05-21T17:51:32+0000","dateStarted":"2018-05-21T17:51:20+0000","results":{"code":"SUCCESS","msg":[]}},{"text":"%pyspark\nhombres = {}\nfor entidad in decateml.filter((decateml.cve_mun == 0) & (decateml.cve_loc == 0)).select('nom_loc').distinct().rdd.flatMap(list).collect():\n    un_resultado = defun_2016.select(\"causa_def\",\"ent_ocurr\",\"sexo\",\"edad\").filter(defun_2016.edad == '4053').join(decateml.filter((decateml.cve_mun == 0) & (decateml.cve_loc == 0)),defun_2016.ent_ocurr == decateml.cve_ent).select(\"sexo\",\"nom_loc\",\"causa_def\").filter((col(\"sexo\") == 1) & (col(\"nom_loc\") == entidad)).groupby('causa_def').agg(functions.count('causa_def').alias('cuenta')).sort(desc('cuenta'))\n    if(un_resultado.count()>0):\n        hombres[entidad] = un_resultado.join((un_resultado.select(\"cuenta\")\n            .distinct()\n            .orderBy(desc(\"cuenta\"))\n            .rdd\n            .zipWithIndex()\n            .map(lambda x: x[0] + (x[1], ))\n            .toDF([\"cuenta\", \"rank\"])), [\"cuenta\"]).withColumn(\"rank\", col(\"rank\") + 1).orderBy(\"cuenta\").filter(col(\"rank\") < 7).join(decatcausa, decatcausa.CVE == col(\"causa_def\")).select(\"DESCRIP\", \"cuenta\", \"rank\")\n            \nfor key in hombres.keys():\n    print(key)\n    print(hombres[key].show())\n    hombres[key].write.parquet(\"s3://examen2granescala/output4b/hombres/proto.parquet\")","user":"anonymous","dateUpdated":"2018-05-21T18:04:59+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1526925080217_62050208","id":"20180521-175120_1611060877","dateCreated":"2018-05-21T17:51:20+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:934","dateFinished":"2018-05-21T18:04:46+0000","dateStarted":"2018-05-21T18:04:46+0000","errorMessage":"java.net.ConnectException: Connection refused (Connection refused)\n\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n\tat java.net.Socket.connect(Socket.java:589)\n\tat org.apache.thrift.transport.TSocket.open(TSocket.java:182)\n\tat org.apache.zeppelin.interpreter.remote.ClientFactory.create(ClientFactory.java:51)\n\tat org.apache.zeppelin.interpreter.remote.ClientFactory.create(ClientFactory.java:37)\n\tat org.apache.commons.pool2.BasePooledObjectFactory.makeObject(BasePooledObjectFactory.java:60)\n\tat org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:861)\n\tat org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:435)\n\tat org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:363)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterProcess.getClient(RemoteInterpreterProcess.java:92)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.interpret(RemoteInterpreter.java:352)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:97)\n\tat org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:406)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:175)\n\tat org.apache.zeppelin.scheduler.RemoteScheduler$JobRunner.run(RemoteScheduler.java:329)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","results":"org.apache.zeppelin.interpreter.InterpreterException: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused (Connection refused)"},{"text":"%pyspark\nmujeres = {}\nfor entidad in decateml.filter((decateml.cve_mun == 0) & (decateml.cve_loc == 0)).select('nom_loc').distinct().rdd.flatMap(list).collect():\n    un_resultado = defun_2016.select(\"causa_def\",\"ent_ocurr\",\"sexo\",\"edad\").filter(defun_2016.edad == '4053').join(decateml.filter((decateml.cve_mun == 0) & (decateml.cve_loc == 0)),defun_2016.ent_ocurr == decateml.cve_ent).select(\"sexo\",\"nom_loc\",\"causa_def\").filter((col(\"sexo\") == 2) & (col(\"nom_loc\") == entidad)).groupby('causa_def').agg(functions.count('causa_def').alias('cuenta')).sort(desc('cuenta'))\n    if(un_resultado.count()>0):\n        mujeres[entidad] = un_resultado.join((un_resultado.select(\"cuenta\")\n            .distinct()\n            .orderBy(desc(\"cuenta\"))\n            .rdd\n            .zipWithIndex()\n            .map(lambda x: x[0] + (x[1], ))\n            .toDF([\"cuenta\", \"rank\"])), [\"cuenta\"]).withColumn(\"rank\", col(\"rank\") + 1).orderBy(\"cuenta\").filter(col(\"rank\") < 7).join(decatcausa, decatcausa.CVE == col(\"causa_def\")).select(\"DESCRIP\", \"cuenta\", \"rank\")\n            \nfor key in mujeres.keys():\n    print(key)\n    print(mujeres[key].show())\n    mujeres[key].write.parquet(\"s3://examen2granescala/output4b/mujeres/proto.parquet\")","user":"anonymous","dateUpdated":"2018-05-21T18:04:20+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1526925133427_1144977155","id":"20180521-175213_1093115642","dateCreated":"2018-05-21T17:52:13+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1003","dateFinished":"2018-05-21T17:59:59+0000","dateStarted":"2018-05-21T17:52:50+0000","errorMessage":"org.apache.thrift.transport.TTransportException\n\tat org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132)\n\tat org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)\n\tat org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)\n\tat org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:69)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.recv_interpret(RemoteInterpreterService.java:266)\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.interpret(RemoteInterpreterService.java:250)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.interpret(RemoteInterpreter.java:373)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:97)\n\tat org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:406)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:175)\n\tat org.apache.zeppelin.scheduler.RemoteScheduler$JobRunner.run(RemoteScheduler.java:329)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","results":"org.apache.thrift.transport.TTransportException"},{"text":"%pyspark\nfrom pyspark.ml.clustering import KMeans\nfrom pyspark.ml.evaluation import ClusteringEvaluator\nfrom pyspark.ml.feature import VectorAssembler, VectorIndexer\nfrom pyspark.sql.functions import monotonically_increasing_id\nfrom pyspark.sql.functions import isnan, when, count, col\n\ndf_feat = defun_2016.select(*(defun_2016[c].cast(\"float\").alias(c) for c in defun_2016.columns[1:]))\ndf_feat = df_feat.withColumn(\"id\", monotonically_increasing_id())\ncantidad_nulos = df_feat.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_feat.columns])\ndf_feat = df_feat.drop(\"causa_def\", \"lista_mex\", \"maternas\", \"gr_lismex\")\nFEATURES_COL = df_feat.drop(\"id\").columns\nvecAssembler = VectorAssembler(inputCols=FEATURES_COL, outputCol=\"features\")\ndf_kmeans = vecAssembler.transform(df_feat).select('id', 'features')\n\ncost = np.zeros(20)\nfor k in range(2,20):\n    kmeans = KMeans().setK(k).setSeed(1).setFeaturesCol(\"features\")\n    model = kmeans.fit(df_kmeans.sample(False,0.1, seed=105898))\n    cost[k] = model.computeCost(df_kmeans)\n\nkmeans = KMeans().setK(13).setSeed(1).setFeaturesCol(\"features\")\nmodel = kmeans.fit(df_kmeans.sample(False,0.1, seed=105898))\n\ntransformed = model.transform(df_kmeans).select('id', 'prediction')\nrows = transformed.collect()\n\ndf_pred = sqlContext.createDataFrame(rows)\n\ndf_pred = df_pred.join(df_feat, 'id')\n\nparticiones = {}\nfor k in range(1,13):\n    particiones[k] = df_pred.filter(col(\"prediction\") == k).write.parquet(\"s3://examen2granescala/output5a/particiones/proto.parquet\")","user":"anonymous","dateUpdated":"2018-05-21T18:04:01+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1526925337577_1155104865","id":"20180521-175537_832100691","dateCreated":"2018-05-21T17:55:37+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1374"}],"name":"Examen2Spark","id":"2DEB5DJGR","angularObjects":{"2BRWU4WXC:shared_process":[],"2AM1YV5CU:shared_process":[],"2AJXGMUUJ:shared_process":[],"2ANGGHHMQ:shared_process":[],"2AKK3QQXU:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}