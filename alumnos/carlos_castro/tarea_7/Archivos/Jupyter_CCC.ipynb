{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pyspark \n",
    "#Cargamos las funcionalidades de spark en el notebook\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "    \n",
    "flights = spark.read.load('flights.csv',format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Como vimos en clase, algunas variables necesitan ser modificadas para ser utilizadas en los modelos de ML\n",
    "#la mayor parte de este código fue tomada directamente de las notas de clase y documentación\n",
    "#Hacemos los arreglos necesarios a las varibles, hot encoder y tokenizer\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "variables = [\"AIRLINE\",\"ORIGIN_AIRPORT\",\"DESTINATION_AIRPORT\",\"DAY_OF_WEEK\"]\n",
    "variables_string_encoded=[\"AIRLINE_strenc\",\"ORIGIN_AIRPORT_strenc\",\"DESTINATION_AIRPORT_strenc\",\"DAY_OF_WEEK_strenc\"]\n",
    "\n",
    "stage_string = [StringIndexer(inputCol= c, outputCol= c+\"_strenc\") for c in variables]\n",
    "stage_one_hot = [OneHotEncoder(inputCol= c+\"_strenc\", outputCol= c+ \"_one_hot\") for c in variables]\n",
    "\n",
    "ppl = Pipeline(stages= stage_string + stage_one_hot)\n",
    "flights = ppl.fit(flights).transform(flights)\n",
    "\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"CANCELLATION_REASON\", outputCol=\"CANCELLATION_REASON_tok\")\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"CANCELLATION_REASON_hash\")\n",
    "\n",
    "\n",
    "flights = flights.dropna(how='any', thresh=None, subset=[\"YEAR\",\"MONTH\",\"DAY\",\"FLIGHT_NUMBER\",\"SCHEDULED_DEPARTURE\",\"DEPARTURE_TIME\",\"TAXI_OUT\", \"WHEELS_OFF\", \"SCHEDULED_TIME\",\"ELAPSED_TIME\",\"AIR_TIME\",\"DISTANCE\",\"WHEELS_OFF\",\"SCHEDULED_TIME\", \"ARRIVAL_TIME\",\"ARRIVAL_DELAY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "579"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Antes de pasar mis datos a un cluster de AWS voy a probar mi código localmente utilizando una imagen de Spark en Jupyter\n",
    "#https://medium.com/@suci/running-pyspark-on-jupyter-notebook-with-docker-602b18ac4494\n",
    "flights = flights.sample(False, .0001, 103531)\n",
    "flights.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparo mis datos\n",
    "#A diferencia del ejecicio visto en clase, es necesario definir un conjunto de variables explicativas \n",
    "#para poder utilizar los modelo de ML. Tomaremos las variables que ya transformamos junto con algunas  \n",
    "#de las originales para formar el vector \"features\" que fungirá como variables explicativas de la regresión.\n",
    "#En clase únicamente fue necesario genera un dataset con el nombre de las columnas que se necesita, \n",
    "#aquí tenemos que \"empaquetar\" algunas variables para utilizarlas como X en nuestros modelos de ML.\n",
    "\n",
    "#Para los 2 modelos de ML que voy a utilizar(regresión lineal y random forest) utilizaré el mismo vector \"features\"\n",
    "#Para definir el vetor de features para mi regresión lineal\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "variables_int=[\"YEAR\",\"MONTH\",\"DAY\",\"FLIGHT_NUMBER\",\"SCHEDULED_DEPARTURE\",\"DEPARTURE_TIME\",\"TAXI_OUT\",\n",
    "              \"WHEELS_OFF\", \"SCHEDULED_TIME\",\"ELAPSED_TIME\",\"AIR_TIME\",\"DISTANCE\",\"WHEELS_OFF\",\"SCHEDULED_TIME\",\n",
    "              \"ARRIVAL_TIME\",\"ARRIVAL_DELAY\"]\n",
    "\n",
    "variables_trans=[\"AIRLINE_one_hot\",\"ORIGIN_AIRPORT_one_hot\",\"DESTINATION_AIRPORT_one_hot\",\"DAY_OF_WEEK_one_hot\"]\n",
    "\n",
    "#Este es el paquete de variables explicativas que voy a considerar en mi ejercicio:\n",
    "features = variables_int + variables_trans\n",
    "\n",
    "vector_assembler = VectorAssembler(inputCols = features, outputCol= \"features\")\n",
    "\n",
    "flights = vector_assembler.transform(flights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "396"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Separamos en entrenamiento y prueba\n",
    "train = flights.sample(False, 0.7, 103531)\n",
    "test = flights.subtract(train)\n",
    "train.count()#Tamaño de nuestro conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#El primer modelo para la predicción del DEPARTURE_DELAY será el modelo de regresión lineal\n",
    "#Nota: primero voy a probar el correcto funcionamiento de mis modelos de forma individual. \n",
    "# --- Regresión Lineal ---\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "#lr =  LinearRegression(labelCol = \"DEPARTURE_DELAY\", featuresCol = \"features\", maxIter = 20)\n",
    "#lr_model = lr.fit(train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator \n",
    "\n",
    "very_small_sample = flights.sample(False, 0.1).cache()\n",
    "\n",
    "#pca_model = PCA(inputCol = \"features\", outputCol = \"features_cv\")\n",
    "lr = LinearRegression(labelCol = \"DEPARTURE_DELAY\", featuresCol = \"features\")\n",
    "ppl_cv = Pipeline(stages = [lr])\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.maxIter, [5, 10]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "very_small_sample.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval = CrossValidator(estimator = ppl_cv,\n",
    "                        estimatorParamMaps=paramGrid,\n",
    "                        evaluator = RegressionEvaluator(\n",
    "    labelCol=\"DEPARTURE_DELAY\", predictionCol=\"prediction\", metricName=\"rmse\"),\n",
    "                        numFolds= 3)\n",
    "\n",
    "cv_model = crossval.fit(very_small_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cv_model.transform(test)\n",
    "evaluator= RegressionEvaluator(labelCol = \"DEPARTURE_DELAY\", predictionCol=\"prediction\", metricName= \"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+\n",
      "|DEPARTURE_DELAY|         prediction|\n",
      "+---------------+-------------------+\n",
      "|             10|-20.957390861362413|\n",
      "|             -8| 4.1462204339933795|\n",
      "|              4|-2.6883326485872256|\n",
      "|              6|  24.95880530663274|\n",
      "|             21| -4.354242736651701|\n",
      "+---------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"DEPARTURE_DELAY\",\"prediction\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.4639266305365\n"
     ]
    }
   ],
   "source": [
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LinearRegression_4dec9ca4104234617391', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2)'): 2,\n",
       " Param(parent='LinearRegression_4dec9ca4104234617391', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty'): 0.0,\n",
       " Param(parent='LinearRegression_4dec9ca4104234617391', name='epsilon', doc='The shape parameter to control the amount of robustness. Must be > 1.0.'): 1.35,\n",
       " Param(parent='LinearRegression_4dec9ca4104234617391', name='featuresCol', doc='features column name'): 'features',\n",
       " Param(parent='LinearRegression_4dec9ca4104234617391', name='fitIntercept', doc='whether to fit an intercept term'): True,\n",
       " Param(parent='LinearRegression_4dec9ca4104234617391', name='labelCol', doc='label column name'): 'DEPARTURE_DELAY',\n",
       " Param(parent='LinearRegression_4dec9ca4104234617391', name='loss', doc='The loss function to be optimized. Supported options: squaredError, huber. (Default squaredError)'): 'squaredError',\n",
       " Param(parent='LinearRegression_4dec9ca4104234617391', name='maxIter', doc='maximum number of iterations (>= 0)'): 5,\n",
       " Param(parent='LinearRegression_4dec9ca4104234617391', name='predictionCol', doc='prediction column name'): 'prediction',\n",
       " Param(parent='LinearRegression_4dec9ca4104234617391', name='regParam', doc='regularization parameter (>= 0)'): 0.0,\n",
       " Param(parent='LinearRegression_4dec9ca4104234617391', name='solver', doc='The solver algorithm for optimization. Supported options: auto, normal, l-bfgs. (Default auto)'): 'auto',\n",
       " Param(parent='LinearRegression_4dec9ca4104234617391', name='standardization', doc='whether to standardize the training features before fitting the model'): True,\n",
       " Param(parent='LinearRegression_4dec9ca4104234617391', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0)'): 1e-06}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model.bestModel.stages[0].extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "(training_data, test_data) = flights.randomSplit([0.7, 0.3])\n",
    "rf = RandomForestRegressor(labelCol = \"DEPARTURE_DELAY\", featuresCol = \"features\", numTrees = 20)\n",
    "rf_model = rf.fit(training_data)\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator \n",
    "\n",
    "very_small_sample = flights.sample(False, 0.1).cache()\n",
    "\n",
    "#pca_model = PCA(inputCol = \"features\", outputCol = \"features_cv\")\n",
    "rf = RandomForestRegressor(labelCol = \"DEPARTURE_DELAY\", featuresCol = \"features\")\n",
    "ppl_cv = Pipeline(stages = [rf])\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [20, 30]) \\\n",
    "    .addGrid(rf.maxDepth,[5,10]) \\\n",
    "    .build()\n",
    "    \n",
    "crossval = CrossValidator(estimator = ppl_cv,\n",
    "                        estimatorParamMaps=paramGrid,\n",
    "                        evaluator = RegressionEvaluator(\n",
    "    labelCol=\"DEPARTURE_DELAY\", predictionCol=\"prediction\", metricName=\"rmse\"),\n",
    "                        numFolds= 3)\n",
    "\n",
    "cv_model = crossval.fit(very_small_sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cv_model.transform(test_data)\n",
    "evaluator= RegressionEvaluator(labelCol = \"DEPARTURE_DELAY\", predictionCol=\"prediction\", metricName= \"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+\n",
      "|DEPARTURE_DELAY|         prediction|\n",
      "+---------------+-------------------+\n",
      "|             -5| 24.303759340731663|\n",
      "|              7|-0.8809879290405336|\n",
      "|             -2| 2.8170616673917506|\n",
      "|             -4|   16.7674110156983|\n",
      "|             11| 23.025632126269063|\n",
      "+---------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"DEPARTURE_DELAY\",\"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.80727095918729\n"
     ]
    }
   ],
   "source": [
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "         'RF': RandomForestRegressor(labelCol = \"DEPARTURE_DELAY\", featuresCol = \"features\"),\n",
    "         'LR': LinearRegression(labelCol = \"DEPARTURE_DELAY\", featuresCol = \"features\")}\n",
    "\n",
    "grid = {\n",
    "    \"RF\":ParamGridBuilder() \\\n",
    "    .addGrid(rf.maxDepth, [ 10,5]) \\\n",
    "    .addGrid(rf.numTrees,[20, 30]) \\\n",
    "    .build(),\n",
    "    \n",
    "    \"LR\":ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [.05, .1]) \\\n",
    "    .addGrid(lr.maxIter,[5,10]) \\\n",
    "    .build()\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista=[\"RF\",\"LR\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF\n",
      "+---------------+------------------+\n",
      "|DEPARTURE_DELAY|        prediction|\n",
      "+---------------+------------------+\n",
      "|             -5|17.113580745341615|\n",
      "|              7| 9.236200023421874|\n",
      "|             -2| 3.865986367887004|\n",
      "|             -4|18.035189940743912|\n",
      "|             11|10.845072310679843|\n",
      "+---------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      "40.80727095918729\n",
      "{Param(parent='RandomForestRegressor_46bfb9012de17dc7b8fd', name='cacheNodeIds', doc='If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees.'): False, Param(parent='RandomForestRegressor_46bfb9012de17dc7b8fd', name='checkpointInterval', doc='set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext'): 10, Param(parent='RandomForestRegressor_46bfb9012de17dc7b8fd', name='featureSubsetStrategy', doc='The number of features to consider for splits at each tree node. Supported options: auto, all, onethird, sqrt, log2, (0.0-1.0], [1-n].'): 'auto', Param(parent='RandomForestRegressor_46bfb9012de17dc7b8fd', name='featuresCol', doc='features column name'): 'features', Param(parent='RandomForestRegressor_46bfb9012de17dc7b8fd', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: variance'): 'variance', Param(parent='RandomForestRegressor_46bfb9012de17dc7b8fd', name='labelCol', doc='label column name'): 'DEPARTURE_DELAY', Param(parent='RandomForestRegressor_46bfb9012de17dc7b8fd', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32, Param(parent='RandomForestRegressor_46bfb9012de17dc7b8fd', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='RandomForestRegressor_46bfb9012de17dc7b8fd', name='maxMemoryInMB', doc='Maximum memory in MB allocated to histogram aggregation.'): 256, Param(parent='RandomForestRegressor_46bfb9012de17dc7b8fd', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0, Param(parent='RandomForestRegressor_46bfb9012de17dc7b8fd', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split.  If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='RandomForestRegressor_46bfb9012de17dc7b8fd', name='numTrees', doc='Number of trees to train (>= 1)'): 20, Param(parent='RandomForestRegressor_46bfb9012de17dc7b8fd', name='predictionCol', doc='prediction column name'): 'prediction', Param(parent='RandomForestRegressor_46bfb9012de17dc7b8fd', name='seed', doc='random seed'): -8211633189720755812, Param(parent='RandomForestRegressor_46bfb9012de17dc7b8fd', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}\n",
      "LR\n",
      "+---------------+-------------------+\n",
      "|DEPARTURE_DELAY|         prediction|\n",
      "+---------------+-------------------+\n",
      "|             -5| 24.303759340731663|\n",
      "|              7|-0.8809879290405336|\n",
      "|             -2| 2.8170616673917506|\n",
      "|             -4|   16.7674110156983|\n",
      "|             11| 23.025632126269063|\n",
      "+---------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      "35.28734126414375\n",
      "{Param(parent='LinearRegression_4756bcc6c22cf88bf1ae', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2)'): 2, Param(parent='LinearRegression_4756bcc6c22cf88bf1ae', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty'): 0.0, Param(parent='LinearRegression_4756bcc6c22cf88bf1ae', name='epsilon', doc='The shape parameter to control the amount of robustness. Must be > 1.0.'): 1.35, Param(parent='LinearRegression_4756bcc6c22cf88bf1ae', name='featuresCol', doc='features column name'): 'features', Param(parent='LinearRegression_4756bcc6c22cf88bf1ae', name='fitIntercept', doc='whether to fit an intercept term'): True, Param(parent='LinearRegression_4756bcc6c22cf88bf1ae', name='labelCol', doc='label column name'): 'DEPARTURE_DELAY', Param(parent='LinearRegression_4756bcc6c22cf88bf1ae', name='loss', doc='The loss function to be optimized. Supported options: squaredError, huber. (Default squaredError)'): 'squaredError', Param(parent='LinearRegression_4756bcc6c22cf88bf1ae', name='maxIter', doc='maximum number of iterations (>= 0)'): 100, Param(parent='LinearRegression_4756bcc6c22cf88bf1ae', name='predictionCol', doc='prediction column name'): 'prediction', Param(parent='LinearRegression_4756bcc6c22cf88bf1ae', name='regParam', doc='regularization parameter (>= 0)'): 0.0, Param(parent='LinearRegression_4756bcc6c22cf88bf1ae', name='solver', doc='The solver algorithm for optimization. Supported options: auto, normal, l-bfgs. (Default auto)'): 'auto', Param(parent='LinearRegression_4756bcc6c22cf88bf1ae', name='standardization', doc='whether to standardize the training features before fitting the model'): True, Param(parent='LinearRegression_4756bcc6c22cf88bf1ae', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0)'): 1e-06}\n"
     ]
    }
   ],
   "source": [
    "classifiers[lista[0]]\n",
    "for i in range(1,3):\n",
    "    modelo = classifiers[lista[i-1]]\n",
    "    modelo_cv = modelo\n",
    "    paramGrid=grid[lista[i-1]]\n",
    "    \n",
    "    crossval = CrossValidator(estimator = modelo_cv,\n",
    "                        estimatorParamMaps=paramGrid,\n",
    "                        evaluator = RegressionEvaluator(\n",
    "    labelCol=\"DEPARTURE_DELAY\", predictionCol=\"prediction\", metricName=\"rmse\"),\n",
    "                        numFolds= 2)\n",
    "\n",
    "    cv_model = crossval.fit(very_small_sample)\n",
    "    \n",
    "    \n",
    "    predictions = cv_model.transform(test_data)\n",
    "    evaluat< or= RegressionEvaluator(labelCol = \"DEPARTURE_DELAY\", predictionCol=\"prediction\", metricName= \"rmse\")\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    print(lista[i-1])\n",
    "    print(predictions.select(\"DEPARTURE_DELAY\",\"prediction\").show(5))\n",
    "    print(rmse)\n",
    "    print(cv_model.bestModel.extractParamMap())\n",
    "    i=i+1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval = CrossValidator(estimator = modelo_cv,\n",
    "                        estimatorParamMaps=paramGrid,\n",
    "                        evaluator = RegressionEvaluator(\n",
    "    labelCol=\"DEPARTURE_DELAY\", predictionCol=\"prediction\", metricName=\"rmse\"),\n",
    "                        numFolds= 3)\n",
    "\n",
    "cv_model = crossval.fit(very_small_sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+\n",
      "|DEPARTURE_DELAY|         prediction|\n",
      "+---------------+-------------------+\n",
      "|             -5| 24.303759340731663|\n",
      "|              7|-0.8809879290405336|\n",
      "|             -2| 2.8170616673917506|\n",
      "|             -4|   16.7674110156983|\n",
      "|             11| 23.025632126269063|\n",
      "+---------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      "35.28734126414375\n"
     ]
    }
   ],
   "source": [
    "predictions = cv_model.transform(test_data)\n",
    "evaluator= RegressionEvaluator(labelCol = \"DEPARTURE_DELAY\", predictionCol=\"prediction\", metricName= \"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(predictions.select(\"DEPARTURE_DELAY\",\"prediction\").show(5))\n",
    "print(rmse)\n",
    "#print(cv_model.bestModel.stages[0].extractParamMap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Param(parent='LinearRegression_4756bcc6c22cf88bf1ae', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2)'): 2, Param(parent='LinearRegression_4756bcc6c22cf88bf1ae', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty'): 0.0, Param(parent='LinearRegression_4756bcc6c22cf88bf1ae', name='epsilon', doc='The shape parameter to control the amount of robustness. Must be > 1.0.'): 1.35, Param(parent='LinearRegression_4756bcc6c22cf88bf1ae', name='featuresCol', doc='features column name'): 'features', Param(parent='LinearRegression_4756bcc6c22cf88bf1ae', name='fitIntercept', doc='whether to fit an intercept term'): True, Param(parent='LinearRegression_4756bcc6c22cf88bf1ae', name='labelCol', doc='label column name'): 'DEPARTURE_DELAY', Param(parent='LinearRegression_4756bcc6c22cf88bf1ae', name='loss', doc='The loss function to be optimized. Supported options: squaredError, huber. (Default squaredError)'): 'squaredError', Param(parent='LinearRegression_4756bcc6c22cf88bf1ae', name='maxIter', doc='maximum number of iterations (>= 0)'): 100, Param(parent='LinearRegression_4756bcc6c22cf88bf1ae', name='predictionCol', doc='prediction column name'): 'prediction', Param(parent='LinearRegression_4756bcc6c22cf88bf1ae', name='regParam', doc='regularization parameter (>= 0)'): 0.0, Param(parent='LinearRegression_4756bcc6c22cf88bf1ae', name='solver', doc='The solver algorithm for optimization. Supported options: auto, normal, l-bfgs. (Default auto)'): 'auto', Param(parent='LinearRegression_4756bcc6c22cf88bf1ae', name='standardization', doc='whether to standardize the training features before fitting the model'): True, Param(parent='LinearRegression_4756bcc6c22cf88bf1ae', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0)'): 1e-06}\n"
     ]
    }
   ],
   "source": [
    "    print(cv_model.bestModel.extractParamMap())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
